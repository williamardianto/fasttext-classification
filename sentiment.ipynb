{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb        sentiment-data-v2.csv\r\n",
      "\u001b[34mfastText\u001b[m\u001b[m              sentiment.ipynb\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3685, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/sentiment-data-v2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Lebih-lebih lagi dengan  kemudahan internet da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>boleh memberi teguran kepada parti tetapi perl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Adalah membingungkan mengapa masyarakat Cina b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Kami menurunkan defisit daripada 6.7 peratus p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ini masalahnya. Bukan rakyat, tetapi sistem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Negative  Lebih-lebih lagi dengan  kemudahan internet da...\n",
       "1  Positive  boleh memberi teguran kepada parti tetapi perl...\n",
       "2  Negative  Adalah membingungkan mengapa masyarakat Cina b...\n",
       "3  Positive  Kami menurunkan defisit daripada 6.7 peratus p...\n",
       "4  Negative        Ini masalahnya. Bukan rakyat, tetapi sistem"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# train.to_csv('train.csv', index=False)\n",
    "# valid.to_csv('valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Negative</td>\n",
       "      <td>menteri kabinet beliau sendiri bercakap mengen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Selain itu, Muslimat Pas juga ingin mencadangk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Apa yang boleh disimpulkan sekarang adalah ia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>Positive</td>\n",
       "      <td>tidak mahu ketinggalan daripada arus pembangun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Kita akan berhubung dengan pihak berkuasa Sing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "1001  Negative  menteri kabinet beliau sendiri bercakap mengen...\n",
       "2494  Positive  Selain itu, Muslimat Pas juga ingin mencadangk...\n",
       "1284  Negative  Apa yang boleh disimpulkan sekarang adalah ia ...\n",
       "1151  Positive  tidak mahu ketinggalan daripada arus pembangun...\n",
       "3630  Positive  Kita akan berhubung dengan pihak berkuasa Sing..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Positive</td>\n",
       "      <td>asean yang dianggotai sepuluh negara terletak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Pertubuhan Makanan dan Pertanian, sebuah agens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>Negative</td>\n",
       "      <td>usaha mengaburi mata dan perasaan orang Melayu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Negative</td>\n",
       "      <td>jika terdapat unsur kecuaian hasil daripada pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Peruntukan bagi pembinaan bangunan sekolah bah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "2023  Positive  asean yang dianggotai sepuluh negara terletak ...\n",
       "2587  Positive  Pertubuhan Makanan dan Pertanian, sebuah agens...\n",
       "3222  Negative     usaha mengaburi mata dan perasaan orang Melayu\n",
       "1263  Negative  jika terdapat unsur kecuaian hasil daripada pe...\n",
       "781   Positive  Peruntukan bagi pembinaan bangunan sekolah bah..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(x):\n",
    "#     x = x.split(' ')\n",
    "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "    for n_gram in n_grams:\n",
    "        x.append(' '.join(n_gram))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menteri',\n",
       " 'kabinet',\n",
       " 'beliau',\n",
       " 'sendiri',\n",
       " 'bercakap',\n",
       " 'mengenai',\n",
       " 'pembinaan',\n",
       " 'hospital',\n",
       " 'kerajaan',\n",
       " 'sakit',\n",
       " 'bekalan',\n",
       " 'ubat',\n",
       " 'di',\n",
       " 'hospital',\n",
       " 'kerajaan',\n",
       " 'yang',\n",
       " 'sering',\n",
       " 'terputus',\n",
       " 'dan',\n",
       " 'pesakit',\n",
       " 'yang',\n",
       " 'dulu',\n",
       " 'mampu',\n",
       " 'berubat',\n",
       " 'di',\n",
       " 'klinik',\n",
       " 'dan',\n",
       " 'hospital',\n",
       " 'swasta',\n",
       " 'kini',\n",
       " 'berpusu-pusu',\n",
       " 'ke',\n",
       " 'klinik',\n",
       " 'dan',\n",
       " 'hospital',\n",
       " 'awam',\n",
       " 'berubat di',\n",
       " 'terputus dan',\n",
       " 'di hospital',\n",
       " 'kini berpusu-pusu',\n",
       " 'yang dulu',\n",
       " 'hospital awam',\n",
       " 'pesakit yang',\n",
       " 'pembinaan hospital',\n",
       " 'dan hospital',\n",
       " 'swasta kini',\n",
       " 'yang sering',\n",
       " 'menteri kabinet',\n",
       " 'beliau sendiri',\n",
       " 'mengenai pembinaan',\n",
       " 'di klinik',\n",
       " 'sakit bekalan',\n",
       " 'bekalan ubat',\n",
       " 'dan pesakit',\n",
       " 'dulu mampu',\n",
       " 'berpusu-pusu ke',\n",
       " 'mampu berubat',\n",
       " 'hospital swasta',\n",
       " 'kerajaan yang',\n",
       " 'kabinet beliau',\n",
       " 'bercakap mengenai',\n",
       " 'ubat di',\n",
       " 'klinik dan',\n",
       " 'kerajaan sakit',\n",
       " 'ke klinik',\n",
       " 'hospital kerajaan',\n",
       " 'sendiri bercakap',\n",
       " 'sering terputus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bigrams(train.iloc[0]['text'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy', preprocessing=generate_bigrams)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_fields = [\n",
    "    ('label', LABEL), # process it as label\n",
    "    ('text', TEXT) # process it as text\n",
    "]\n",
    "\n",
    "trainds, valds = data.TabularDataset.splits(path='./data/', \n",
    "                                            format='csv', \n",
    "                                            train='train.csv', \n",
    "                                            validation='valid.csv', \n",
    "                                            fields=train_val_fields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('label', <torchtext.data.field.LabelField object at 0x1a18e55b00>), ('text', <torchtext.data.field.Field object at 0x1a18df30f0>)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainds.fields.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = trainds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menteri',\n",
       " 'kabinet',\n",
       " 'beliau',\n",
       " 'sendiri',\n",
       " 'bercakap',\n",
       " 'mengenai',\n",
       " 'pembinaan',\n",
       " 'hospital',\n",
       " 'kerajaan',\n",
       " 'sakit',\n",
       " 'bekalan',\n",
       " 'ubat',\n",
       " 'di',\n",
       " 'hospital',\n",
       " 'kerajaan',\n",
       " 'yang',\n",
       " 'sering',\n",
       " 'terputus',\n",
       " 'dan',\n",
       " 'pesakit',\n",
       " 'yang',\n",
       " 'dulu',\n",
       " 'mampu',\n",
       " 'berubat',\n",
       " 'di',\n",
       " 'klinik',\n",
       " 'dan',\n",
       " 'hospital',\n",
       " 'swasta',\n",
       " 'kini',\n",
       " 'berpusu',\n",
       " '-',\n",
       " 'pusu',\n",
       " 'ke',\n",
       " 'klinik',\n",
       " 'dan',\n",
       " 'hospital',\n",
       " 'awam',\n",
       " 'kabinet beliau',\n",
       " 'di hospital',\n",
       " 'terputus dan',\n",
       " 'yang dulu',\n",
       " 'mampu berubat',\n",
       " 'kini berpusu',\n",
       " 'sendiri bercakap',\n",
       " 'pembinaan hospital',\n",
       " 'berubat di',\n",
       " 'ke klinik',\n",
       " 'berpusu -',\n",
       " 'ubat di',\n",
       " 'yang sering',\n",
       " 'pusu ke',\n",
       " 'sering terputus',\n",
       " 'hospital swasta',\n",
       " 'di klinik',\n",
       " '- pusu',\n",
       " 'hospital kerajaan',\n",
       " 'hospital awam',\n",
       " 'dan hospital',\n",
       " 'klinik dan',\n",
       " 'bercakap mengenai',\n",
       " 'pesakit yang',\n",
       " 'mengenai pembinaan',\n",
       " 'kerajaan sakit',\n",
       " 'beliau sendiri',\n",
       " 'bekalan ubat',\n",
       " 'kerajaan yang',\n",
       " 'menteri kabinet',\n",
       " 'dulu mampu',\n",
       " 'swasta kini',\n",
       " 'dan pesakit',\n",
       " 'sakit bekalan']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainds)\n",
    "LABEL.build_vocab(trainds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Negative']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), # specify train and validation Tabulardataset\n",
    "                                            batch_sizes=(3,3),  # batch size of train and validation\n",
    "#                                             sort_key=lambda x: len(x.SentimentText), # on what attribute the text should be sorted\n",
    "                                            device=None, # -1 mean cpu and 0 or None mean gpu\n",
    "#                                             sort_within_batch=True, \n",
    "                                            sort=False,\n",
    "                                            repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983 246\n"
     ]
    }
   ],
   "source": [
    "print(len(traindl), len(valdl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([[17523,  3682,    35],\n",
      "        [  841,   111,     7],\n",
      "        [23110,     9,  4615],\n",
      "        [  285,   111,  1278],\n",
      "        [ 3422,   688,    17],\n",
      "        [ 4952,     6,     7],\n",
      "        [26033,    91,  1960],\n",
      "        [ 1422,    12,  1276],\n",
      "        [  200, 28791,   433],\n",
      "        [   31,    24,   146],\n",
      "        [ 2546,    19,  1367],\n",
      "        [19364,  1073,     3],\n",
      "        [  715,   891,  1006],\n",
      "        [  132,     3,   701],\n",
      "        [    9,   172,   722],\n",
      "        [  132, 30344, 31767],\n",
      "        [  112,    24, 41882],\n",
      "        [  173,  1173, 27476],\n",
      "        [    7,  1622, 34515],\n",
      "        [ 2953,  4701, 17363],\n",
      "        [ 2573,  1906,  1322],\n",
      "        [ 2566,    68, 34278],\n",
      "        [  200,   275,  9619],\n",
      "        [  760,   234, 33189],\n",
      "        [  132, 17213,  2200],\n",
      "        [  450,     5,     1],\n",
      "        [    7, 28476,     1],\n",
      "        [  537, 40373,     1],\n",
      "        [  742, 17214,     1],\n",
      "        [   30,  6324,     1],\n",
      "        [ 1954, 30345,     1],\n",
      "        [ 8657, 26296,     1],\n",
      "        [    4, 29867,     1],\n",
      "        [  200, 36472,     1],\n",
      "        [ 3199, 40214,     1],\n",
      "        [    7,  1331,     1],\n",
      "        [   86,  5126,     1],\n",
      "        [   90,  1461,     1],\n",
      "        [  418, 14203,     1],\n",
      "        [    8, 34925,     1],\n",
      "        [ 1663, 21420,     1],\n",
      "        [  480,   868,     1],\n",
      "        [ 1602, 28792,     1],\n",
      "        [ 2397, 40510,     1],\n",
      "        [    7,  3004,     1],\n",
      "        [ 2829, 13686,     1],\n",
      "        [   13, 26315,     1],\n",
      "        [ 4220,  7623,     1],\n",
      "        [  112,  7587,     1],\n",
      "        [  173,  1917,     1],\n",
      "        [26999,  1074,     1],\n",
      "        [19365,     1,     1],\n",
      "        [23875,     1,     1],\n",
      "        [17524,     1,     1],\n",
      "        [42062,     1,     1],\n",
      "        [40288,     1,     1],\n",
      "        [38696,     1,     1],\n",
      "        [38191,     1,     1],\n",
      "        [17485,     1,     1],\n",
      "        [19005,     1,     1],\n",
      "        [17033,     1,     1],\n",
      "        [23111,     1,     1],\n",
      "        [41762,     1,     1],\n",
      "        [41746,     1,     1],\n",
      "        [39743,     1,     1],\n",
      "        [ 6678,     1,     1],\n",
      "        [ 4006,     1,     1],\n",
      "        [32575,     1,     1],\n",
      "        [ 3408,     1,     1],\n",
      "        [ 6012,     1,     1],\n",
      "        [26034,     1,     1],\n",
      "        [20033,     1,     1],\n",
      "        [19156,     1,     1],\n",
      "        [ 1765,     1,     1],\n",
      "        [ 2045,     1,     1],\n",
      "        [31078,     1,     1],\n",
      "        [ 6928,     1,     1],\n",
      "        [ 9402,     1,     1],\n",
      "        [18815,     1,     1],\n",
      "        [ 5039,     1,     1],\n",
      "        [ 5018,     1,     1],\n",
      "        [35450,     1,     1],\n",
      "        [ 7317,     1,     1],\n",
      "        [37224,     1,     1],\n",
      "        [29066,     1,     1],\n",
      "        [ 5085,     1,     1],\n",
      "        [18113,     1,     1],\n",
      "        [35458,     1,     1],\n",
      "        [30984,     1,     1],\n",
      "        [40995,     1,     1],\n",
      "        [ 4721,     1,     1],\n",
      "        [  280,     1,     1],\n",
      "        [34536,     1,     1],\n",
      "        [21774,     1,     1],\n",
      "        [31667,     1,     1],\n",
      "        [40159,     1,     1],\n",
      "        [39080,     1,     1],\n",
      "        [24341,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(traindl)) # BucketIterator return a batch object\n",
    "# print(type(batch))\n",
    "# torchtext.data.batch.Batch\n",
    "\n",
    "print(batch.label) # labels of the batch\n",
    "# tensor([ 0,  0,  0], device='cuda:0')\n",
    "\n",
    "print(batch.text) # text index and length of the batch\n",
    "# (tensor([[  204,   107,   956],\n",
    "#         [   29,  3176,   112],\n",
    "#         [ 4391,   195,    28],\n",
    "#         [ 1413,    57,    57],\n",
    "#         [   19,    32,    26],\n",
    "#         [   32,   114,  5138]], device='cuda:0'),\n",
    "# tensor([ 6,  6,  6], device='cuda:0'))\n",
    "\n",
    "# print(batch.dataset.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "        \n",
    "        #pooled = [batch size, embedding_dim]\n",
    "                \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = FastText(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.654 | Train Acc: 64.43% | Val. Loss: 0.619 | Val. Acc: 66.40% |\n",
      "| Epoch: 02 | Train Loss: 0.577 | Train Acc: 66.77% | Val. Loss: 0.574 | Val. Acc: 68.02% |\n",
      "| Epoch: 03 | Train Loss: 0.441 | Train Acc: 80.84% | Val. Loss: 0.535 | Val. Acc: 73.17% |\n",
      "| Epoch: 04 | Train Loss: 0.289 | Train Acc: 92.51% | Val. Loss: 0.510 | Val. Acc: 74.80% |\n",
      "| Epoch: 05 | Train Loss: 0.176 | Train Acc: 97.52% | Val. Loss: 0.501 | Val. Acc: 74.12% |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, traindl, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valdl, criterion)\n",
    "#     print(train_loss, train_acc)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_acc = evaluate(model, valdl, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_sentiment(\"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('asean yang dianggotai sepuluh negara terletak di rantau asia tenggara yang mengandungi kepelbagaian agama bangsa dan budaya serta banyak jurang perbezaan dalam kalangan anggota asean dari aspek ekonomi politik keselamatan dan sosio-budaya',\n",
       " 'Positive')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[0]['text'], valid.iloc[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pertubuhan Makanan dan Pertanian, sebuah agensi Pertubuhan Bangsa-Bangsa Bersatu, menjangka pada tahun 2050 penduduk dunia akan mencecah 9.1 bilion orang dan untuk menepati permintaan, pengeluaran makanan perlu ditingkatkan sebanyak 70 peratus.',\n",
       " 'Positive')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[1]['text'], valid.iloc[1]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('usaha mengaburi mata dan perasaan orang Melayu', 'Negative')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[2]['text'], valid.iloc[2]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jika terdapat unsur kecuaian hasil daripada penyiasatan itu, maka, kakitangan yang terlibat akan dikenakan tindakan tegas.',\n",
       " 'Negative')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[3]['text'], valid.iloc[3]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Peruntukan bagi pembinaan bangunan sekolah baharu itu nanti akan dimasukkan bersama dalam projek memperbaiki sekolah yang terjejas teruk akibat banjir, baru-baru ini',\n",
       " 'Positive')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[4]['text'], valid.iloc[4]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sebaliknya kebajikan mereka jadi bertambah teruk akibat penghapusan subsidi dan kejatuhan kadar tukaran ringgit yang secara langsung menyebabkan harga barang dan perkhidmatan naik',\n",
       " 'Positive')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.iloc[5]['text'], valid.iloc[5]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949637651443481"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(valid.iloc[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'Positive': 0, 'Negative': 1})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
