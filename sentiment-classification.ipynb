{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentiment_mapping ={\n",
    "    'Positive': 1,\n",
    "    'Negative': 0,\n",
    "    'Neutral': 2,\n",
    "    'neutral': 2\n",
    "}\n",
    "\n",
    "sentiment_mapping2 ={\n",
    "    'pos': 1,\n",
    "    'neg': 0,\n",
    "    'neu': 2\n",
    "}\n",
    "\n",
    "sentiment_mapping_reverse ={\n",
    "    1: 'Positive',\n",
    "    0: 'Negative',\n",
    "    2: 'Neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText as ft\n",
    "word_vectors=ft.load_fasttext_format(\"cc.ms.300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60115, 15)\n",
      "(13260, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_excel('./data/vala_processed.xlsx')\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(['CONTENT'])\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BN</th>\n",
       "      <th>PH</th>\n",
       "      <th>PAS</th>\n",
       "      <th>General</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" # elections news : did najib just pocket the...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt rt untuk tun mahathir . love untuk najib ra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt who is arguably the best malaysia ' s prime...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" a year of dread and foreboding in the malays...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" mr najib may be venal , but he is not stupid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  #hashtags  #urls  \\\n",
       "0  \" # elections news : did najib just pocket the...          2      0   \n",
       "1  rt rt untuk tun mahathir . love untuk najib ra...          1      0   \n",
       "2  rt who is arguably the best malaysia ' s prime...          0      0   \n",
       "3  \" a year of dread and foreboding in the malays...          0      0   \n",
       "4  \" mr najib may be venal , but he is not stupid...          0      0   \n",
       "\n",
       "   #mentions  #word  #capital  #pos_emojis  #neg_emojis  #emojis  \\\n",
       "0          0     21         0            0            0        0   \n",
       "1          0     12         3            0            0        0   \n",
       "2          0     23         2            0            0        1   \n",
       "3          0     27         1            0            0        0   \n",
       "4          0     35         0            0            0        0   \n",
       "\n",
       "   #exclaimation_question sentiment  BN  PH  PAS  General  sentiment_label  \n",
       "0                       1  Negative   1   0    0        0                0  \n",
       "1                       0  Positive   1   0    0        0                1  \n",
       "2                       1  Positive   1   0    0        0                1  \n",
       "3                       0  Negative   1   0    0        0                0  \n",
       "4                       0  Negative   1   0    0        0                0  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_label'] = df['sentiment'].map(lambda x: sentiment_mapping[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "error_index = []\n",
    "for i, row in df.iterrows():\n",
    "#     print(i)\n",
    "    try:\n",
    "        content_split = row['CONTENT'].split()\n",
    "        for word in content_split:\n",
    "            word_vectors.wv[word]\n",
    "    except:\n",
    "        error_list.append(word)\n",
    "        error_index.append(i)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!¬¥',\n",
       " '!‚Äù',\n",
       " '!‚Ä¶',\n",
       " '\"‚Äî',\n",
       " '\"‚Äò',\n",
       " '\"‚Äú',\n",
       " '\"‚Ä¶',\n",
       " \"'‚Ä¶\",\n",
       " '(‚Ä¶',\n",
       " ')‚Ä¶',\n",
       " ',‚Äù',\n",
       " ',‚Ä¶',\n",
       " '-‚Äò',\n",
       " '-‚Ä¶',\n",
       " '.‚Äô',\n",
       " '.‚Äù',\n",
       " '.‚Ä¶',\n",
       " '/‚Ä¶',\n",
       " '0k',\n",
       " '3j',\n",
       " '5o',\n",
       " ':‚Ä¶',\n",
       " ';‚Ä¶',\n",
       " '?‚Äô',\n",
       " '?‚Äù',\n",
       " '?‚Ä¶',\n",
       " '`',\n",
       " 'election',\n",
       " 'q4',\n",
       " '~¬∞',\n",
       " '“Ø—Ä',\n",
       " '◊¢◊ì',\n",
       " 'ÿ£',\n",
       " 'Ÿé',\n",
       " 'Ÿè',\n",
       " '‡ÆÖ‡Æü',\n",
       " '‡ÆÖ‡Æ©',\n",
       " '‡Æé‡Æü',\n",
       " '‡Æé‡Æµ',\n",
       " '‡Æì‡Æ≤',\n",
       " '‡Æ£',\n",
       " '‡ÆÆ',\n",
       " '‡ÆÆ‡Æ≤',\n",
       " '‡Æø',\n",
       " '‡ØÄ',\n",
       " '‡ØÅ',\n",
       " '‡ØÇ',\n",
       " '‡Øá',\n",
       " '‡Øä',\n",
       " '‡∏±',\n",
       " '‡∏µ‡πâ',\n",
       " '‡∏∂',\n",
       " '‡∏∏',\n",
       " '‡∫ª',\n",
       " '·Äô',\n",
       " '‚Äî‚Ä¶',\n",
       " '‚Äò\"',\n",
       " '‚Äò‚Äú',\n",
       " '‚Äô,',\n",
       " '‚Äô.',\n",
       " '‚Äô:',\n",
       " '‚Äô‚Ä¶',\n",
       " '‚Äú#',\n",
       " '‚Äù)',\n",
       " '‚Äù,',\n",
       " '‚Äù.',\n",
       " '‚Äù:',\n",
       " '‚Äù?',\n",
       " '‚Äù‚Ä¶',\n",
       " '‚ÄùÔºü',\n",
       " '‚Ç¨‚Äú',\n",
       " '‚ãÜ',\n",
       " '‚ãØ',\n",
       " '‚íà',\n",
       " '‚ó§‚Äú',\n",
       " '‚òû',\n",
       " '‚öò',\n",
       " '„ÄÇ#',\n",
       " '„ÄÇ‚Ä¶',\n",
       " '‰∏Ä‰πù',\n",
       " 'Âç≥ÊôÇ',\n",
       " 'ÊãõÊï∞',\n",
       " 'ËìùÁúº',\n",
       " 'Ìò∏Ïïº',\n",
       " 'Ìôî',\n",
       " 'Ô∏è.',\n",
       " 'Ô∏è@',\n",
       " 'Ôºâ!',\n",
       " 'ÔºâÔºÅ',\n",
       " 'ÔºâÔºõ',\n",
       " 'Ôºå#',\n",
       " 'üèº',\n",
       " 'üèΩ',\n",
       " 'üèæ'}"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(error_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11573, 16), (1286, 16))"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(data.Dataset):\n",
    "    def __init__(self, df, scaler, training=True):\n",
    "        self.data = df\n",
    "        self.scaler = scaler\n",
    "        self.tweet = self.data[['CONTENT']]\n",
    "        self.training = training\n",
    "        self.metadata = self.data[['#hashtags','#urls','#mentions','#word','#capital','#pos_emojis','#neg_emojis','#emojis','#exclaimation_question']]\n",
    "        \n",
    "        if training:\n",
    "            self.party_label = self.data[['PH','BN','PAS','General']]\n",
    "            self.sentiment_label = self.data[['sentiment_label']]\n",
    "            self.metadata = scaler.fit_transform(self.metadata)\n",
    "        else:\n",
    "            self.metadata = scaler.transform(self.metadata)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def prepareVector(self, sentence):\n",
    "        sentence = sentence.split()\n",
    "        featureVec = np.zeros(300)\n",
    "        nwords = 0\n",
    "\n",
    "        for word in sentence:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,word_vectors.wv[word])\n",
    "\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         sentence = self.data.iloc[index, 1]\n",
    "#         sentiment_label = self.data.iloc[index, 2]\n",
    "#         party_label = self.data.iloc[index, 'PH','BN','PAS','General']\n",
    "#         print(self.tweet.iloc[index])\n",
    "        wordFeature = self.prepareVector(self.tweet.iloc[index].values[0])\n",
    "        metadataFeature = self.metadata[index]\n",
    "        \n",
    "        feature = np.concatenate([wordFeature, metadataFeature])\n",
    "        \n",
    "        if self.training:\n",
    "            sentLabel = self.sentiment_label.iloc[index].values\n",
    "            partyLabel = self.party_label.iloc[index].values\n",
    "            \n",
    "            return feature, sentLabel[0], partyLabel\n",
    "        else:\n",
    "            return feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = TwitterDataset(df=train_df, scaler=scaler, training=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, num_workers=4)\n",
    "\n",
    "val_dataset = TwitterDataset(df=val_df, scaler= scaler, training=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 309]) torch.Size([32]) torch.Size([32, 4])\n",
      "torch.float64 torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "feature, sentLabel, partyLabel = next(iter(train_loader))\n",
    "print(feature.size(), sentLabel.size(), partyLabel.size())\n",
    "print(feature.dtype, sentLabel.dtype, partyLabel.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(309, 1000) \n",
    "        self.fc2 = nn.Linear(1000, 500) \n",
    "        self.fc3 = nn.Linear(500, 100)\n",
    "        self.sentiment_layer = nn.Linear(100, 3)\n",
    "        self.party_layer = nn.Linear(100, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        sentiment_output = self.sentiment_layer(x)\n",
    "        party_output = torch.sigmoid(self.party_layer(x))\n",
    "        return sentiment_output, party_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 309])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# net.train()\n",
    "# net(feature.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_criterion = nn.CrossEntropyLoss()\n",
    "party_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)  \n",
    "\n",
    "data_loaders = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/362], Loss: 1.0836\n",
      "Epoch [1/50], Step [200/362], Loss: 1.4084\n",
      "Epoch [1/50], Step [300/362], Loss: 1.2143\n",
      "Validation Sentiment Accuracy: 52.33281493001555 %\n",
      "Validation Party Accuracy: 85.23247528076172 %\n",
      "Epoch [2/50], Step [100/362], Loss: 1.0039\n",
      "Epoch [2/50], Step [200/362], Loss: 1.2811\n",
      "Epoch [2/50], Step [300/362], Loss: 1.1304\n",
      "Validation Sentiment Accuracy: 56.37636080870917 %\n",
      "Validation Party Accuracy: 86.58536529541016 %\n",
      "Epoch [3/50], Step [100/362], Loss: 0.9560\n",
      "Epoch [3/50], Step [200/362], Loss: 1.1824\n",
      "Epoch [3/50], Step [300/362], Loss: 1.0529\n",
      "Validation Sentiment Accuracy: 58.39813374805599 %\n",
      "Validation Party Accuracy: 87.32850646972656 %\n",
      "Epoch [4/50], Step [100/362], Loss: 0.8987\n",
      "Epoch [4/50], Step [200/362], Loss: 1.1039\n",
      "Epoch [4/50], Step [300/362], Loss: 1.0118\n",
      "Validation Sentiment Accuracy: 59.33125972006221 %\n",
      "Validation Party Accuracy: 87.78582000732422 %\n",
      "Epoch [5/50], Step [100/362], Loss: 0.8487\n",
      "Epoch [5/50], Step [200/362], Loss: 1.0683\n",
      "Epoch [5/50], Step [300/362], Loss: 0.9664\n",
      "Validation Sentiment Accuracy: 60.186625194401245 %\n",
      "Validation Party Accuracy: 87.93826293945312 %\n",
      "Epoch [6/50], Step [100/362], Loss: 0.8171\n",
      "Epoch [6/50], Step [200/362], Loss: 1.0356\n",
      "Epoch [6/50], Step [300/362], Loss: 0.9312\n",
      "Validation Sentiment Accuracy: 59.25349922239502 %\n",
      "Validation Party Accuracy: 88.14786529541016 %\n",
      "Epoch [7/50], Step [100/362], Loss: 0.7804\n",
      "Epoch [7/50], Step [200/362], Loss: 0.9990\n",
      "Epoch [7/50], Step [300/362], Loss: 0.8971\n",
      "Validation Sentiment Accuracy: 60.342146189735615 %\n",
      "Validation Party Accuracy: 88.39557647705078 %\n",
      "Epoch [8/50], Step [100/362], Loss: 0.7479\n",
      "Epoch [8/50], Step [200/362], Loss: 0.9410\n",
      "Epoch [8/50], Step [300/362], Loss: 0.8586\n",
      "Validation Sentiment Accuracy: 60.9642301710731 %\n",
      "Validation Party Accuracy: 88.4718017578125 %\n",
      "Epoch [9/50], Step [100/362], Loss: 0.7160\n",
      "Epoch [9/50], Step [200/362], Loss: 0.8568\n",
      "Epoch [9/50], Step [300/362], Loss: 0.7836\n",
      "Validation Sentiment Accuracy: 62.44167962674961 %\n",
      "Validation Party Accuracy: 88.4718017578125 %\n",
      "Epoch [10/50], Step [100/362], Loss: 0.6524\n",
      "Epoch [10/50], Step [200/362], Loss: 0.7924\n",
      "Epoch [10/50], Step [300/362], Loss: 0.7272\n",
      "Validation Sentiment Accuracy: 62.44167962674961 %\n",
      "Validation Party Accuracy: 88.3193588256836 %\n",
      "Epoch [11/50], Step [100/362], Loss: 0.5957\n",
      "Epoch [11/50], Step [200/362], Loss: 0.7284\n",
      "Epoch [11/50], Step [300/362], Loss: 0.7101\n",
      "Validation Sentiment Accuracy: 63.530326594090205 %\n",
      "Validation Party Accuracy: 88.52896118164062 %\n",
      "Epoch [12/50], Step [100/362], Loss: 0.5431\n",
      "Epoch [12/50], Step [200/362], Loss: 0.6831\n",
      "Epoch [12/50], Step [300/362], Loss: 0.6131\n",
      "Validation Sentiment Accuracy: 63.60808709175739 %\n",
      "Validation Party Accuracy: 88.4718017578125 %\n",
      "Epoch [13/50], Step [100/362], Loss: 0.5214\n",
      "Epoch [13/50], Step [200/362], Loss: 0.6203\n",
      "Epoch [13/50], Step [300/362], Loss: 0.5649\n",
      "Validation Sentiment Accuracy: 63.29704510108865 %\n",
      "Validation Party Accuracy: 89.1006088256836 %\n",
      "Epoch [14/50], Step [100/362], Loss: 0.5501\n",
      "Epoch [14/50], Step [200/362], Loss: 0.6015\n",
      "Epoch [14/50], Step [300/362], Loss: 0.5234\n",
      "Validation Sentiment Accuracy: 62.13063763608087 %\n",
      "Validation Party Accuracy: 88.98627471923828 %\n",
      "Epoch [15/50], Step [100/362], Loss: 0.5129\n",
      "Epoch [15/50], Step [200/362], Loss: 0.5636\n",
      "Epoch [15/50], Step [300/362], Loss: 0.4273\n",
      "Validation Sentiment Accuracy: 61.35303265940902 %\n",
      "Validation Party Accuracy: 89.19588470458984 %\n",
      "Epoch [16/50], Step [100/362], Loss: 0.4172\n",
      "Epoch [16/50], Step [200/362], Loss: 0.5144\n",
      "Epoch [16/50], Step [300/362], Loss: 0.4568\n",
      "Validation Sentiment Accuracy: 62.519440124416796 %\n",
      "Validation Party Accuracy: 89.15777587890625 %\n",
      "Epoch [17/50], Step [100/362], Loss: 0.3739\n",
      "Epoch [17/50], Step [200/362], Loss: 0.4336\n",
      "Epoch [17/50], Step [300/362], Loss: 0.4292\n",
      "Validation Sentiment Accuracy: 63.685847589424576 %\n",
      "Validation Party Accuracy: 89.40548706054688 %\n",
      "Epoch [18/50], Step [100/362], Loss: 0.3957\n",
      "Epoch [18/50], Step [200/362], Loss: 0.4242\n",
      "Epoch [18/50], Step [300/362], Loss: 0.3005\n",
      "Validation Sentiment Accuracy: 62.90824261275272 %\n",
      "Validation Party Accuracy: 89.21493530273438 %\n",
      "Epoch [19/50], Step [100/362], Loss: 0.2806\n",
      "Epoch [19/50], Step [200/362], Loss: 0.5433\n",
      "Epoch [19/50], Step [300/362], Loss: 0.3332\n",
      "Validation Sentiment Accuracy: 63.84136858475894 %\n",
      "Validation Party Accuracy: 89.11966705322266 %\n",
      "Epoch [20/50], Step [100/362], Loss: 0.2137\n",
      "Epoch [20/50], Step [200/362], Loss: 0.4443\n",
      "Epoch [20/50], Step [300/362], Loss: 0.2923\n",
      "Validation Sentiment Accuracy: 63.919129082426124 %\n",
      "Validation Party Accuracy: 89.42454528808594 %\n",
      "Epoch [21/50], Step [100/362], Loss: 0.2959\n",
      "Epoch [21/50], Step [200/362], Loss: 0.3172\n",
      "Epoch [21/50], Step [300/362], Loss: 0.2810\n",
      "Validation Sentiment Accuracy: 64.15241057542768 %\n",
      "Validation Party Accuracy: 88.662353515625 %\n",
      "Epoch [22/50], Step [100/362], Loss: 0.2707\n",
      "Epoch [22/50], Step [200/362], Loss: 0.3018\n",
      "Epoch [22/50], Step [300/362], Loss: 0.3230\n",
      "Validation Sentiment Accuracy: 64.23017107309487 %\n",
      "Validation Party Accuracy: 88.79573059082031 %\n",
      "Epoch [23/50], Step [100/362], Loss: 0.2534\n",
      "Epoch [23/50], Step [200/362], Loss: 0.3544\n",
      "Epoch [23/50], Step [300/362], Loss: 0.2585\n",
      "Validation Sentiment Accuracy: 65.31881804043546 %\n",
      "Validation Party Accuracy: 88.81478881835938 %\n",
      "Epoch [24/50], Step [100/362], Loss: 0.2341\n",
      "Epoch [24/50], Step [200/362], Loss: 0.2860\n",
      "Epoch [24/50], Step [300/362], Loss: 0.2058\n",
      "Validation Sentiment Accuracy: 65.78538102643857 %\n",
      "Validation Party Accuracy: 89.42454528808594 %\n",
      "Epoch [25/50], Step [100/362], Loss: 0.1504\n",
      "Epoch [25/50], Step [200/362], Loss: 0.2531\n",
      "Epoch [25/50], Step [300/362], Loss: 0.2282\n",
      "Validation Sentiment Accuracy: 65.70762052877139 %\n",
      "Validation Party Accuracy: 89.443603515625 %\n",
      "Epoch [26/50], Step [100/362], Loss: 0.2316\n",
      "Epoch [26/50], Step [200/362], Loss: 0.2212\n",
      "Epoch [26/50], Step [300/362], Loss: 0.1834\n",
      "Validation Sentiment Accuracy: 62.67496111975117 %\n",
      "Validation Party Accuracy: 89.74847412109375 %\n",
      "Epoch [27/50], Step [100/362], Loss: 0.1435\n",
      "Epoch [27/50], Step [200/362], Loss: 0.1494\n",
      "Epoch [27/50], Step [300/362], Loss: 0.1126\n",
      "Validation Sentiment Accuracy: 64.23017107309487 %\n",
      "Validation Party Accuracy: 89.6531982421875 %\n",
      "Epoch [28/50], Step [100/362], Loss: 0.1307\n",
      "Epoch [28/50], Step [200/362], Loss: 0.1422\n",
      "Epoch [28/50], Step [300/362], Loss: 0.1859\n",
      "Validation Sentiment Accuracy: 63.530326594090205 %\n",
      "Validation Party Accuracy: 89.57698059082031 %\n",
      "Epoch [29/50], Step [100/362], Loss: 0.0913\n",
      "Epoch [29/50], Step [200/362], Loss: 0.1560\n",
      "Epoch [29/50], Step [300/362], Loss: 0.1121\n",
      "Validation Sentiment Accuracy: 63.530326594090205 %\n",
      "Validation Party Accuracy: 89.51981353759766 %\n",
      "Epoch [30/50], Step [100/362], Loss: 0.1094\n",
      "Epoch [30/50], Step [200/362], Loss: 0.2080\n",
      "Epoch [30/50], Step [300/362], Loss: 0.0542\n",
      "Validation Sentiment Accuracy: 64.5412130637636 %\n",
      "Validation Party Accuracy: 89.86280822753906 %\n",
      "Epoch [31/50], Step [100/362], Loss: 0.0885\n",
      "Epoch [31/50], Step [200/362], Loss: 0.1247\n",
      "Epoch [31/50], Step [300/362], Loss: 0.0685\n",
      "Validation Sentiment Accuracy: 62.67496111975117 %\n",
      "Validation Party Accuracy: 89.53887176513672 %\n",
      "Epoch [32/50], Step [100/362], Loss: 0.0906\n",
      "Epoch [32/50], Step [200/362], Loss: 0.4038\n",
      "Epoch [32/50], Step [300/362], Loss: 0.0848\n",
      "Validation Sentiment Accuracy: 63.99688958009331 %\n",
      "Validation Party Accuracy: 89.93902587890625 %\n",
      "Epoch [33/50], Step [100/362], Loss: 0.2056\n",
      "Epoch [33/50], Step [200/362], Loss: 0.3240\n",
      "Epoch [33/50], Step [300/362], Loss: 0.1632\n",
      "Validation Sentiment Accuracy: 64.0746500777605 %\n",
      "Validation Party Accuracy: 89.23399353027344 %\n",
      "Epoch [34/50], Step [100/362], Loss: 0.1106\n",
      "Epoch [34/50], Step [200/362], Loss: 0.2623\n",
      "Epoch [34/50], Step [300/362], Loss: 0.0595\n",
      "Validation Sentiment Accuracy: 66.64074650077761 %\n",
      "Validation Party Accuracy: 88.14786529541016 %\n",
      "Epoch [35/50], Step [100/362], Loss: 0.0859\n",
      "Epoch [35/50], Step [200/362], Loss: 0.1233\n",
      "Epoch [35/50], Step [300/362], Loss: 0.0899\n",
      "Validation Sentiment Accuracy: 64.30793157076205 %\n",
      "Validation Party Accuracy: 88.5099105834961 %\n",
      "Epoch [36/50], Step [100/362], Loss: 0.1460\n",
      "Epoch [36/50], Step [200/362], Loss: 0.1040\n",
      "Epoch [36/50], Step [300/362], Loss: 0.0565\n",
      "Validation Sentiment Accuracy: 65.55209953343702 %\n",
      "Validation Party Accuracy: 87.91920471191406 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [100/362], Loss: 0.1834\n",
      "Epoch [37/50], Step [200/362], Loss: 0.2182\n",
      "Epoch [37/50], Step [300/362], Loss: 0.1490\n",
      "Validation Sentiment Accuracy: 63.99688958009331 %\n",
      "Validation Party Accuracy: 88.64329528808594 %\n",
      "Epoch [38/50], Step [100/362], Loss: 0.0768\n",
      "Epoch [38/50], Step [200/362], Loss: 0.1250\n",
      "Epoch [38/50], Step [300/362], Loss: 0.0531\n",
      "Validation Sentiment Accuracy: 66.40746500777605 %\n",
      "Validation Party Accuracy: 88.52896118164062 %\n",
      "Epoch [39/50], Step [100/362], Loss: 0.0901\n",
      "Epoch [39/50], Step [200/362], Loss: 0.1359\n",
      "Epoch [39/50], Step [300/362], Loss: 0.1380\n",
      "Validation Sentiment Accuracy: 63.919129082426124 %\n",
      "Validation Party Accuracy: 89.11966705322266 %\n",
      "Epoch [40/50], Step [100/362], Loss: 0.0746\n",
      "Epoch [40/50], Step [200/362], Loss: 0.2301\n",
      "Epoch [40/50], Step [300/362], Loss: 0.0466\n",
      "Validation Sentiment Accuracy: 65.0855365474339 %\n",
      "Validation Party Accuracy: 88.94817352294922 %\n",
      "Epoch [41/50], Step [100/362], Loss: 0.0812\n",
      "Epoch [41/50], Step [200/362], Loss: 0.1071\n",
      "Epoch [41/50], Step [300/362], Loss: 0.0523\n",
      "Validation Sentiment Accuracy: 65.39657853810264 %\n",
      "Validation Party Accuracy: 89.51981353759766 %\n",
      "Epoch [42/50], Step [100/362], Loss: 0.0405\n",
      "Epoch [42/50], Step [200/362], Loss: 0.0593\n",
      "Epoch [42/50], Step [300/362], Loss: 0.0789\n",
      "Validation Sentiment Accuracy: 64.38569206842924 %\n",
      "Validation Party Accuracy: 89.0625 %\n",
      "Epoch [43/50], Step [100/362], Loss: 0.0937\n",
      "Epoch [43/50], Step [200/362], Loss: 0.0640\n",
      "Epoch [43/50], Step [300/362], Loss: 0.0218\n",
      "Validation Sentiment Accuracy: 65.00777604976672 %\n",
      "Validation Party Accuracy: 89.17682647705078 %\n",
      "Epoch [44/50], Step [100/362], Loss: 0.0291\n",
      "Epoch [44/50], Step [200/362], Loss: 0.0659\n",
      "Epoch [44/50], Step [300/362], Loss: 0.3458\n",
      "Validation Sentiment Accuracy: 64.38569206842924 %\n",
      "Validation Party Accuracy: 89.53887176513672 %\n",
      "Epoch [45/50], Step [100/362], Loss: 0.1196\n",
      "Epoch [45/50], Step [200/362], Loss: 0.1778\n",
      "Epoch [45/50], Step [300/362], Loss: 0.0181\n",
      "Validation Sentiment Accuracy: 65.31881804043546 %\n",
      "Validation Party Accuracy: 89.69131469726562 %\n",
      "Epoch [46/50], Step [100/362], Loss: 0.1188\n",
      "Epoch [46/50], Step [200/362], Loss: 0.0431\n",
      "Epoch [46/50], Step [300/362], Loss: 0.0300\n",
      "Validation Sentiment Accuracy: 64.5412130637636 %\n",
      "Validation Party Accuracy: 89.51981353759766 %\n",
      "Epoch [47/50], Step [100/362], Loss: 0.2277\n",
      "Epoch [47/50], Step [200/362], Loss: 0.2262\n",
      "Epoch [47/50], Step [300/362], Loss: 0.0268\n",
      "Validation Sentiment Accuracy: 63.60808709175739 %\n",
      "Validation Party Accuracy: 89.59603881835938 %\n",
      "Epoch [48/50], Step [100/362], Loss: 0.0540\n",
      "Epoch [48/50], Step [200/362], Loss: 0.0968\n",
      "Epoch [48/50], Step [300/362], Loss: 0.0566\n",
      "Validation Sentiment Accuracy: 64.69673405909798 %\n",
      "Validation Party Accuracy: 89.38643646240234 %\n",
      "Epoch [49/50], Step [100/362], Loss: 0.2167\n",
      "Epoch [49/50], Step [200/362], Loss: 0.0633\n",
      "Epoch [49/50], Step [300/362], Loss: 0.1583\n",
      "Validation Sentiment Accuracy: 63.919129082426124 %\n",
      "Validation Party Accuracy: 89.38643646240234 %\n",
      "Epoch [50/50], Step [100/362], Loss: 0.0279\n",
      "Epoch [50/50], Step [200/362], Loss: 0.0423\n",
      "Epoch [50/50], Step [300/362], Loss: 0.1321\n",
      "Validation Sentiment Accuracy: 62.363919129082426 %\n",
      "Validation Party Accuracy: 88.85289764404297 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            for i, (features, sentLabel, partyLabel) in enumerate(data_loaders[phase]):  \n",
    "                # Move tensors to the configured device\n",
    "                features = features.float()\n",
    "                partyLabel = partyLabel.type(torch.FloatTensor)\n",
    "\n",
    "                # Forward pass\n",
    "                output_sent, output_party = net(features)\n",
    "\n",
    "                sent_loss = sent_criterion(output_sent, sentLabel)\n",
    "                party_loss = party_criterion(output_party, partyLabel)\n",
    "#                 print((output_party.round() == partyLabel).type(torch.FloatTensor).sum()/(32*4))\n",
    "                loss = sent_loss + party_loss\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                party_accuracy = 0\n",
    "                for i, (features, sentLabel, partyLabel) in enumerate(data_loaders[phase]):  \n",
    "                    features = features.float()\n",
    "                    partyLabel = partyLabel.type(torch.FloatTensor)\n",
    "                    \n",
    "                    output_sent, output_party = net(features)\n",
    "                    \n",
    "                    # calculate sentiment accuracy\n",
    "                    _, predicted = torch.max(output_sent.data, 1)\n",
    "                    total += sentLabel.size(0)\n",
    "                    correct += (predicted == sentLabel).sum().item()\n",
    "                    \n",
    "                    # calculate party accuracy\n",
    "                    party_accuracy += (output_party.round() == partyLabel).type(torch.FloatTensor).sum()/(32*4)\n",
    "                    \n",
    "                print('Validation Sentiment Accuracy: {} %'.format(100 * correct / total))\n",
    "                print('Validation Party Accuracy: {} %'.format(100 * (party_accuracy/len(data_loaders[phase]))))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.1771,  0.3051,  0.2256,  ..., -0.0169, -0.0924,  0.0713],\n",
       "                      [-0.0884, -0.3738,  0.2825,  ...,  0.0090, -0.0578,  0.2121],\n",
       "                      [ 0.6976, -0.1008, -0.3517,  ..., -0.0367, -0.0256,  0.0636],\n",
       "                      ...,\n",
       "                      [ 0.0649,  0.1610, -0.9014,  ...,  0.1054,  0.1381,  0.1164],\n",
       "                      [ 0.0152, -0.7118,  0.0167,  ...,  0.0539,  0.0582,  0.1090],\n",
       "                      [ 0.1407,  0.0260,  0.0666,  ...,  0.0172, -0.1435, -0.3649]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.1245, -0.5631, -0.3903, -0.2231, -0.1393, -0.4189, -0.0581, -0.2770,\n",
       "                      -0.3721, -0.2303, -0.0339, -0.1062, -0.3938, -0.0569, -0.4054, -0.3984,\n",
       "                      -0.3965, -0.8722, -0.1925, -0.1308, -0.4791, -0.2916, -0.2130, -0.0547,\n",
       "                      -0.3590, -0.2687, -0.2527, -0.1211, -0.1169, -0.2237, -0.2332, -0.1648,\n",
       "                      -0.2108, -0.2857, -0.2500, -0.2328, -0.0891, -0.2743, -0.4051, -0.3213,\n",
       "                      -0.1538, -0.5063, -0.2054, -0.0444, -0.0789, -0.2845, -0.1766, -0.4179,\n",
       "                      -0.1083, -0.2121, -0.0806, -0.1005, -0.0716, -0.1564, -0.2176, -0.5633,\n",
       "                      -0.2855, -0.3100, -0.1553, -0.4987, -0.3163, -0.5086, -0.2477, -0.3261,\n",
       "                      -0.4334, -0.1754, -0.2522, -0.1140, -0.6988, -0.2878, -0.0623, -0.1636,\n",
       "                       0.0545, -0.4059, -0.5769, -0.1658, -0.3911, -0.2341, -0.1833, -0.2550,\n",
       "                      -0.1262, -0.3410, -0.0569, -0.1900, -0.1092, -0.2829, -0.2315, -0.2663,\n",
       "                      -0.3804, -0.2535, -0.4759, -0.2815, -0.2364, -0.3856,  0.0068, -0.1329,\n",
       "                      -0.1379, -0.5686, -0.1368, -0.0890, -0.0621, -0.3489, -0.1673, -0.1381,\n",
       "                      -0.1832, -0.4444, -0.0539, -0.0686, -0.0896, -0.3234, -0.2633, -0.3003,\n",
       "                      -0.3951, -0.4514, -0.2556, -0.4040, -0.3583, -0.2605, -0.2990, -0.1829,\n",
       "                      -0.0298, -0.2108, -0.3553, -0.2653, -0.0609, -0.2355, -0.3091, -0.0916,\n",
       "                      -0.0292,  0.0051, -0.3556, -0.4045, -0.1632, -0.5960, -0.3769, -0.4157,\n",
       "                      -0.1695, -0.1044, -0.2100,  0.0526, -0.3899, -0.1427, -0.4459, -0.3434,\n",
       "                      -0.4323, -0.0608, -0.2076, -0.0718, -0.1855, -0.1898, -0.1947, -0.0612,\n",
       "                      -0.1783, -0.3276, -0.2236, -0.4064, -0.0336, -0.1487, -0.3149, -0.1155,\n",
       "                      -0.2871, -0.3779, -0.3098,  0.0285, -0.3253, -0.2490, -0.2935, -0.1167,\n",
       "                      -0.0741, -0.0390, -0.3021, -0.2789, -0.1559, -0.8758, -0.0948, -0.2493,\n",
       "                      -0.1150, -0.2585, -0.2792, -0.3111, -0.1569, -0.6895, -0.0661, -0.8922,\n",
       "                      -0.3506, -0.3660, -0.4988, -0.1326, -0.1573, -0.7963, -0.1796, -0.3671,\n",
       "                      -0.5155, -0.2429, -0.3341, -0.5055, -0.1485, -0.3078, -0.4899, -0.4384,\n",
       "                      -0.4506, -0.5218,  0.0246, -0.1855, -0.1800, -0.2009, -0.2726, -0.3831,\n",
       "                      -0.3418, -0.3187, -0.1841, -0.1595, -0.1494, -0.2246, -0.0098, -0.2976,\n",
       "                      -0.2864, -0.2909, -0.2198, -0.1481, -0.2140, -0.2934, -0.2154, -0.1238,\n",
       "                      -0.3286, -0.0676, -0.3522, -0.4886, -0.3299, -0.3418, -0.1344, -0.1490,\n",
       "                      -0.1845, -0.6958, -0.2219, -0.3067, -0.0465,  0.0260, -0.5546, -0.2947,\n",
       "                       0.0641, -0.1671, -0.1880, -0.2390, -0.2401, -0.3598, -0.1691, -0.3102,\n",
       "                      -0.0100, -0.1991, -0.3350, -0.0920, -0.2421, -0.2094, -0.4937, -0.2417,\n",
       "                      -0.1147, -0.2443, -0.5294, -0.2540, -0.2493, -0.2396, -0.0994, -0.3646,\n",
       "                      -0.2279, -0.0110, -0.2746, -0.3102, -0.4800, -0.5256, -0.0974, -0.3419,\n",
       "                      -0.2033, -0.0531, -0.5953, -0.3770, -0.2297, -0.1145, -0.3068, -0.1080,\n",
       "                      -0.2683, -0.1593, -0.3437, -0.2606, -0.6012, -0.2816, -0.2021, -0.5969,\n",
       "                      -0.1107, -0.1312, -0.1012, -0.0757, -0.0868, -0.3343, -0.1697, -0.2172,\n",
       "                      -0.1394, -0.3014, -0.2306, -0.1117, -0.1485, -0.2801, -0.3249, -0.3137,\n",
       "                      -0.2627, -0.1795, -0.2008, -0.5226, -0.1204, -0.1759, -0.3345, -0.2734,\n",
       "                      -0.3169, -0.0759, -0.3052, -0.2865, -0.4415, -0.1155, -0.3758, -0.1215,\n",
       "                      -0.1401, -0.2193, -0.1472, -0.1018, -0.0846, -0.1966, -0.1564, -0.2167,\n",
       "                      -0.4766, -0.3387, -0.1598, -0.7388, -0.2239, -0.2161, -0.1120, -0.2071,\n",
       "                      -0.5093, -0.1966, -0.2654, -0.0986,  0.0646, -0.1367, -0.1815, -0.4433,\n",
       "                      -0.1930, -0.3237, -0.2417, -0.2640, -0.1542, -0.4151, -0.3197, -0.3386,\n",
       "                      -0.3651, -0.3565, -0.3138, -0.2286, -0.1998, -0.2261, -0.5718, -0.2046,\n",
       "                      -0.3536,  0.0329, -0.1663, -0.3799, -0.4079, -0.3197, -0.2034, -0.1977,\n",
       "                      -0.1936, -0.3306, -0.2421, -0.3652, -0.1906, -0.1633, -0.0168, -0.2839,\n",
       "                      -0.3481, -0.7176, -0.5579, -0.2163, -0.2046, -0.3955, -0.3942, -0.1768,\n",
       "                      -0.0558, -0.2584, -0.1390, -0.2250, -0.1562, -0.2635, -0.3046, -0.2264,\n",
       "                      -0.4624, -0.1509, -0.4193, -0.1784, -0.0966, -0.1014, -0.1802,  0.0108,\n",
       "                      -0.1755, -0.4599, -0.0447, -0.1580, -0.8180, -0.0817, -0.1438, -0.2858,\n",
       "                      -0.1532, -0.1842, -0.4605, -0.3768, -0.2055, -0.2813, -0.1415, -0.3785,\n",
       "                      -0.2689, -0.3508, -0.3373, -0.1664, -0.2425, -0.4398, -0.2389, -0.0450,\n",
       "                      -0.2220, -0.2617, -0.6444, -0.7447, -0.0157, -0.2298, -0.1491, -0.2373,\n",
       "                      -0.3273, -0.2436, -0.2927, -0.2370, -0.3334, -0.3103, -0.4434, -0.4915,\n",
       "                      -0.1772, -0.2212, -0.1942, -0.1579, -0.5907, -0.0442, -0.2465, -0.3561,\n",
       "                      -0.4428, -0.1597, -0.0526, -0.1354, -0.4593, -0.3279, -0.2017, -0.2509,\n",
       "                      -0.0908, -0.2128, -0.6335, -0.2969, -0.2536, -0.3196, -0.1669, -0.3156,\n",
       "                      -0.5168, -0.1005, -0.2271, -0.1451, -0.1540, -0.2070, -0.3784, -0.1705,\n",
       "                      -0.1259, -0.1520, -0.2884, -0.2972, -0.1093, -0.2405, -0.1558, -0.3026,\n",
       "                      -0.1243, -0.4377, -0.0504, -0.3170, -0.0507, -0.0507, -0.2402, -0.1637,\n",
       "                      -0.1399, -0.0697, -0.3238, -0.2981, -0.1565, -0.4470, -0.2800, -0.1649,\n",
       "                      -0.2282, -0.3933, -0.2524, -0.2562, -0.2394, -0.1898, -0.0930, -0.2777,\n",
       "                      -0.4121, -0.1983, -0.3681, -0.4314, -0.0300, -0.2145, -0.2108, -0.2028,\n",
       "                      -0.3587, -0.6653, -0.0681, -0.2573, -0.2271, -0.3912, -0.1432, -0.2214,\n",
       "                      -0.0921,  0.0189, -0.5627, -0.2003, -0.3648, -0.0418, -0.0416, -0.0742,\n",
       "                      -0.4298, -0.4106, -0.2016, -0.3240, -0.2063, -0.2574, -0.2945, -0.2069,\n",
       "                      -0.1244, -0.5386, -0.2554, -0.4326, -0.2579, -0.1832, -0.2291, -0.2558,\n",
       "                      -0.3807, -0.0885, -0.1033, -0.1191, -0.1230, -0.1795, -0.1219, -0.4003,\n",
       "                      -0.3512, -0.3842, -0.3386, -0.1883, -0.2479, -0.0243, -0.8447, -0.1908,\n",
       "                      -0.1336, -0.1977, -0.1997, -0.1055, -0.3712, -0.1427, -0.2785, -0.2486,\n",
       "                      -0.3075, -0.1561, -0.1371, -0.2021, -0.2087, -0.4072, -0.1396, -0.4592,\n",
       "                      -0.1236, -0.0013, -0.2795, -0.1466, -0.3190, -0.1464, -0.2223, -0.2320,\n",
       "                      -0.3876, -0.5006, -0.2557, -0.5579, -0.1261, -0.1555, -0.1332, -0.1486,\n",
       "                      -0.3700, -0.2258, -0.0880, -0.1858, -0.1187, -0.3744, -0.3729, -0.1675,\n",
       "                      -0.3069, -0.2262, -0.1835, -0.1011, -0.2235, -0.4696, -0.0278, -0.2267,\n",
       "                      -0.1987, -0.2142, -0.2446, -0.2853, -0.2007, -0.2698, -0.4301, -0.1285,\n",
       "                      -0.2425, -0.4544, -0.4980, -0.0837, -0.3593, -0.1911, -0.2827, -0.1250,\n",
       "                      -0.4059, -0.3368, -0.3945, -0.2333, -0.2553, -0.3757, -0.3718, -0.2114,\n",
       "                      -0.1170, -0.3270, -0.1841, -0.2508, -0.3307, -0.6089, -0.3170, -0.1574,\n",
       "                      -0.1948, -0.2733, -0.3237, -0.1243, -0.2758, -0.1037,  0.0284, -0.3338,\n",
       "                      -0.3810, -0.2244, -0.2916, -0.1652, -0.2069, -0.0871, -0.1936, -0.2691,\n",
       "                      -0.1808, -0.2784, -0.0783, -0.1011, -0.2245,  0.0085, -0.1640, -0.3036,\n",
       "                      -0.3024, -0.2207, -0.2062, -0.1043, -0.1714, -0.2735, -0.0755, -0.2138,\n",
       "                      -0.2105, -0.1050,  0.0172, -0.2718, -0.2564, -0.5036, -0.2332, -0.5808,\n",
       "                      -0.1725, -0.0874, -0.1287, -0.2617, -0.2837, -0.0982, -0.1133, -0.1121,\n",
       "                      -0.1429, -0.5790, -0.1961, -0.2111, -0.2864, -0.8416, -0.1272, -0.3129,\n",
       "                      -0.3386, -0.4575, -0.1187, -0.4676, -0.1643, -0.3853, -0.3049, -0.5513,\n",
       "                      -0.3059, -0.3628, -0.1866, -0.1617, -0.3480, -0.1958, -0.3959, -0.3424,\n",
       "                      -0.2269, -0.2542, -0.1910, -0.1136, -0.4283, -0.2079, -0.3001, -0.1251,\n",
       "                      -0.0740, -0.6218, -0.6227, -0.1924, -0.1593, -0.0333, -0.0781, -0.4003,\n",
       "                      -0.2676, -0.0649, -0.1924, -0.2199, -0.2353, -0.1547, -0.1485, -0.2011,\n",
       "                      -0.1197, -0.0596, -0.1062, -0.1289, -0.1668, -0.1494, -0.0467, -0.1594,\n",
       "                      -0.3192, -0.0773, -0.1236, -0.1933, -0.1366, -0.3840, -0.1354, -0.0578,\n",
       "                      -0.0520, -0.2331, -0.0276, -0.2890, -0.3327, -0.5081, -0.0990, -0.4313,\n",
       "                      -0.3741, -0.2284, -0.2572, -0.3233, -0.2708, -0.3243, -0.1720, -0.3771,\n",
       "                      -0.4743, -0.2971, -0.2201, -0.1996, -0.2532, -0.1195, -0.3569, -0.1017,\n",
       "                      -0.2905, -0.3292, -0.2213, -0.1633, -0.0462, -0.5778, -0.2842, -0.3538,\n",
       "                      -0.1382, -0.5476, -0.2789,  0.0120, -0.5948, -0.2910, -0.2294, -0.2239,\n",
       "                      -0.4916, -0.3240, -0.0776, -0.1982, -0.8401, -0.1764, -0.0772, -0.2302,\n",
       "                      -0.2762, -0.2437, -0.1962, -0.1717, -0.3346, -0.2034, -0.0794, -0.8540,\n",
       "                      -0.2977, -0.3061, -0.1434, -0.0564, -0.0668, -0.2575, -0.1455, -0.1127,\n",
       "                      -0.2251, -0.1142, -0.2606, -0.0683, -0.1203, -0.5560, -0.1438, -0.2838,\n",
       "                      -0.2997, -0.3179, -0.3619, -0.3092, -0.1925, -0.1095, -0.1979, -0.1610,\n",
       "                      -0.1015, -0.1372,  0.0127, -0.2581, -0.2429, -0.4292, -0.0974, -0.7339,\n",
       "                      -0.2096, -0.2120, -0.1883, -0.2004, -0.2784, -0.1652, -0.1301, -0.6899,\n",
       "                      -0.2844, -0.3895, -0.3767, -0.2043, -0.1427, -0.2877,  0.0294, -0.3745,\n",
       "                      -0.4730, -0.2956, -0.2368,  0.0465, -0.3206, -0.4029, -0.2955, -0.4226,\n",
       "                      -0.3039, -0.2971, -0.3395, -0.2038,  0.0116, -0.2235, -0.2450, -0.0433,\n",
       "                      -0.1704, -0.2138, -0.2684, -0.2904, -0.1264, -0.2609, -0.1636, -0.1524,\n",
       "                      -0.3282, -0.2420, -0.0710, -0.4724, -0.2980, -0.3041, -0.1813, -0.1294,\n",
       "                      -0.0890, -0.0697, -0.2564, -0.3255, -0.0014, -0.1959, -0.1519, -0.6264,\n",
       "                      -0.3038, -0.2069, -0.2274, -0.1377, -0.2734, -0.1956, -0.4781, -0.1913,\n",
       "                      -0.2474, -0.5702, -0.3697, -0.1795, -0.3515, -0.3913, -0.1366, -0.0230,\n",
       "                      -0.1965, -0.1480, -0.2748, -0.1804, -0.2028, -0.1367, -0.0673, -0.3365,\n",
       "                      -0.3403, -0.1818, -0.4078, -0.4576, -0.1389, -0.3179, -0.4174, -0.2147,\n",
       "                      -0.1085, -0.1728, -0.1233, -0.0649, -0.3714, -0.3015, -0.1449, -0.3086,\n",
       "                      -0.2664, -0.4330, -0.3606, -0.4359, -0.4126, -0.1952, -0.0314, -0.2932,\n",
       "                      -0.5732, -0.2384, -0.5816, -0.8958, -0.3298, -0.3624, -0.3098, -0.1168,\n",
       "                      -0.6691, -0.1728, -0.1369, -0.1952, -0.0830, -0.1950, -0.1436, -0.5008,\n",
       "                      -0.1886, -0.3315, -0.1776, -0.1317, -0.0471, -0.2900, -0.3117, -0.3564,\n",
       "                      -0.1197, -0.1649, -0.2204, -0.4572, -0.2410, -0.0391, -0.3145, -0.4446,\n",
       "                      -0.1146, -0.1526, -0.2237, -0.1157, -0.6674, -0.2204, -0.1674, -0.2231,\n",
       "                      -0.2876, -0.0709, -0.1064, -0.1682, -0.2427, -0.2762, -0.0274, -0.4489,\n",
       "                      -0.1533, -0.4375, -0.1155, -0.2908, -0.1294, -0.0676, -0.1327, -0.0361])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-4.0241e-01, -5.8997e-02,  8.5109e-01,  ...,  3.9363e-01,\n",
       "                        7.6206e-01,  2.6871e-01],\n",
       "                      [ 3.6413e-01, -4.6741e-01, -1.0685e+00,  ..., -3.6490e-01,\n",
       "                       -4.1591e-02,  1.9215e-01],\n",
       "                      [-3.6549e-02,  9.3803e-03, -3.8937e-02,  ..., -3.2138e-02,\n",
       "                        2.0210e-02,  1.6159e-03],\n",
       "                      ...,\n",
       "                      [-5.0366e-02, -1.5161e-02, -3.2171e-02,  ..., -3.8593e-02,\n",
       "                        7.5622e-03,  1.0634e-04],\n",
       "                      [-8.1082e-02,  4.1948e-01, -2.7417e-01,  ..., -6.8832e-03,\n",
       "                        2.4492e-01,  7.5628e-01],\n",
       "                      [ 6.0203e-02, -4.4691e-01, -5.7780e-02,  ..., -3.0499e-01,\n",
       "                       -9.5914e-02, -3.3174e-01]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 1.8850e-02,  2.1229e-01, -3.7764e-02, -7.4444e-02,  3.4460e-02,\n",
       "                      -5.2706e-02,  9.8464e-02,  1.5093e-01, -4.4640e-02, -1.1102e+00,\n",
       "                       1.3147e-01, -1.6468e-01, -3.9602e-02, -1.7239e-02, -8.4032e-01,\n",
       "                       1.0478e-01, -5.7703e-01, -5.4253e-01, -1.2469e-02, -6.2065e-02,\n",
       "                      -4.7041e-02, -5.3566e-02,  2.4215e-02, -2.7386e-01, -4.3937e-02,\n",
       "                      -7.0184e-01, -1.5759e-02,  1.8050e-01, -4.0702e-02, -7.6983e-02,\n",
       "                      -2.0886e-01,  1.7805e-02, -1.8250e-02,  3.0281e-01, -2.0045e-01,\n",
       "                       1.3444e-01,  7.4323e-02,  1.1747e-01, -7.1063e-01, -1.2722e-01,\n",
       "                      -1.0489e-01, -5.4097e-02, -2.4232e-02, -2.2212e-01, -6.1666e-01,\n",
       "                       5.1077e-03, -1.6036e-01, -4.9284e-02, -6.2668e-02, -1.4015e-01,\n",
       "                      -4.6020e-01, -6.7646e-01, -6.2142e-02, -1.1343e-01, -4.6076e-02,\n",
       "                       2.1784e-01, -3.0680e-02, -8.7765e-01, -1.5747e-01, -2.7112e-02,\n",
       "                      -4.4500e-01, -8.8363e-02, -6.2058e-02, -2.5622e-02,  5.0413e-02,\n",
       "                      -1.4435e-01,  7.0377e-02,  8.2854e-02, -6.6441e-02, -1.3597e-01,\n",
       "                      -8.7345e-02, -7.1060e-02, -2.4049e-02, -5.2863e-02,  1.2899e-01,\n",
       "                      -2.8625e-02, -3.3338e-02,  1.4462e-02, -6.0319e-01, -3.8782e-02,\n",
       "                       4.9676e-01,  1.6596e-01, -9.2379e-02, -3.6101e-02,  5.1757e-01,\n",
       "                      -1.7524e-01, -3.7721e-02, -4.2479e-02,  1.5161e-01, -7.2619e-02,\n",
       "                      -1.6812e-02,  4.6730e-01, -6.4415e-01, -8.5086e-02,  3.1318e-02,\n",
       "                       1.0473e-01,  2.3570e-01, -8.8366e-01, -2.2665e-02, -9.0074e-01,\n",
       "                      -1.4001e-02, -9.9178e-01,  6.4223e-03, -6.0607e-02,  2.2312e-01,\n",
       "                      -8.9472e-01, -1.9660e-01, -8.5626e-03, -1.2817e-01, -4.6663e-01,\n",
       "                      -6.8147e-02,  2.1691e-01,  1.2777e-01, -4.8073e-01, -1.2133e-01,\n",
       "                      -5.8917e-02, -2.1455e-01, -3.5548e-02,  5.3075e-02, -1.2063e-01,\n",
       "                      -5.2738e-02, -7.1637e-01, -5.9695e-02, -9.6655e-02, -3.3535e-01,\n",
       "                      -2.4090e-01, -6.6453e-01,  3.3831e-01,  5.1327e-02, -2.6519e-02,\n",
       "                      -1.8843e-01,  2.0365e-02, -6.2769e-01, -2.0125e-01, -1.5718e+00,\n",
       "                      -5.1644e-02, -1.0105e-01, -2.7707e-01,  1.6095e-01, -1.3619e-01,\n",
       "                      -9.1924e-02, -7.8394e-02, -8.8243e-02,  2.4079e-02,  9.7406e-02,\n",
       "                      -3.2998e-01, -4.6494e-02, -1.4920e-01, -2.5880e-01, -5.5196e-02,\n",
       "                      -9.2245e-01, -3.9192e-02, -2.0062e-01, -1.4966e-01, -1.1126e-01,\n",
       "                       1.0935e-01, -2.0104e-01,  1.7748e-01, -4.4374e-02, -6.2596e-02,\n",
       "                      -1.5937e-01, -1.8591e-01, -7.5482e-01, -9.9031e-02,  4.3445e-02,\n",
       "                      -7.9288e-02,  1.7965e-01, -3.2836e-01, -9.1431e-03, -1.0180e-01,\n",
       "                      -1.2761e-01,  1.6303e-01, -3.7828e-02, -2.7139e-01, -2.8405e-01,\n",
       "                      -5.7802e-01, -5.0785e-01, -3.3581e-02,  7.6565e-02,  2.0169e-01,\n",
       "                      -1.8909e-02, -3.1551e-02, -2.1102e-01, -8.5698e-02, -4.6787e-01,\n",
       "                      -2.5071e-01, -2.0303e-01, -1.3147e-01,  1.7260e-01,  8.0869e-02,\n",
       "                      -3.6771e-01,  4.9192e-02,  1.1834e-01, -3.8003e-01,  4.4355e-02,\n",
       "                       3.6276e-02, -5.7543e-02, -1.6105e-01,  1.7860e-01, -9.4989e-02,\n",
       "                       1.8392e-01, -2.4103e-01, -2.1578e-01, -4.9390e-02, -4.9806e-02,\n",
       "                      -2.5845e-02, -1.8762e-01, -1.6798e-02, -5.9706e-01, -1.3797e-01,\n",
       "                      -1.0595e-01, -6.7568e-02,  2.9313e-03, -7.6334e-01, -1.9171e-01,\n",
       "                      -7.6911e-02, -4.8997e-02, -6.3388e-02, -4.9143e-02, -3.2852e-01,\n",
       "                      -6.1185e-02, -5.8072e-02,  2.2159e-01, -4.2672e-01, -7.4488e-02,\n",
       "                       1.2257e-01, -7.9322e-02, -4.0130e-01, -6.5797e-02, -1.3249e-02,\n",
       "                      -3.9911e-02, -6.5934e-02,  2.8945e-02, -1.1156e-01,  5.7517e-02,\n",
       "                       9.6297e-02,  2.9225e-02,  4.7232e-02,  9.1660e-02,  2.7253e-01,\n",
       "                      -9.1841e-02, -2.4520e-01,  2.5715e-03,  1.0598e-02,  5.4903e-01,\n",
       "                      -2.1223e-01,  6.1557e-02, -5.7511e-02,  8.9938e-03, -1.0441e-01,\n",
       "                      -5.7525e-02, -4.9982e-01,  1.5749e-01, -5.7086e-02,  1.8098e-01,\n",
       "                      -2.7221e-02, -5.0042e-01, -5.3094e-01, -5.7472e-02, -2.8799e-02,\n",
       "                      -6.8414e-02, -2.8544e-01,  1.3718e-04, -1.1270e-01, -5.3999e-01,\n",
       "                       4.1886e-02, -6.2857e-02, -5.3437e-02,  1.6413e-01,  1.2205e-01,\n",
       "                       2.6494e-02, -4.7758e-02, -3.0238e-02, -1.9537e-02, -1.4759e-01,\n",
       "                      -2.5340e-01,  1.6743e-01, -3.1503e-01, -6.2896e-01, -1.7920e-02,\n",
       "                      -1.5647e-01, -3.7951e-02,  2.9951e-01, -1.2199e-01,  4.4528e-01,\n",
       "                      -5.0589e-02, -1.3731e-01, -5.4598e-02,  3.4714e-01,  2.5066e-02,\n",
       "                       1.2050e-01, -1.8721e-01, -6.0553e-02, -2.1813e-01, -9.0767e-02,\n",
       "                       1.5809e-01,  4.4681e-02, -6.9474e-01, -5.0364e-02, -2.3780e-02,\n",
       "                      -1.7833e+00, -5.2455e-02,  1.1362e-01, -4.1838e-01, -2.6819e-02,\n",
       "                      -2.2241e-01, -8.1443e-02, -7.0177e-02, -4.3965e-02, -3.7541e-02,\n",
       "                      -3.0982e-01, -1.0653e-01,  1.0410e-01, -4.2169e-02, -2.2754e-01,\n",
       "                       1.0575e-02, -4.3953e-02, -2.2535e-01, -4.8679e-02, -3.9982e-02,\n",
       "                      -1.7143e-02, -5.5514e-01, -2.4256e-01, -1.6575e-01, -8.7202e-02,\n",
       "                      -4.5453e-02, -1.5725e-01, -5.7350e-02, -4.1126e-02, -3.4127e-01,\n",
       "                      -4.1657e-02,  4.1410e-02, -8.6238e-02, -2.2119e-02,  2.6311e-01,\n",
       "                       1.4018e-01, -5.4618e-01, -1.9320e-01, -2.1704e-01, -3.7516e-01,\n",
       "                      -1.3024e-01, -2.6174e-01, -1.6120e-01, -1.1924e-01, -1.8542e-01,\n",
       "                      -3.1780e-01, -1.4013e-01, -4.2711e-02, -1.4429e-01, -2.0323e-01,\n",
       "                      -4.5251e-01, -2.7148e-02,  1.2197e-01, -3.5813e-02,  1.6927e-01,\n",
       "                      -3.2168e-01,  1.2382e-01, -4.1131e-01, -7.5377e-02, -6.5658e-01,\n",
       "                      -1.6822e-02, -4.2328e-01, -1.8222e-01, -2.3384e-02, -1.1505e-02,\n",
       "                       2.4542e-01,  1.0315e-01, -1.9286e-02, -6.4574e-02,  1.7659e-03,\n",
       "                       2.1856e-01,  8.4447e-02, -2.5006e-02, -1.2243e-01,  2.6776e-01,\n",
       "                      -8.7989e-02, -1.7216e-02, -5.4424e-02, -1.8662e-01, -3.7091e-01,\n",
       "                       4.3089e-02, -2.0551e-01, -9.9178e-02,  2.0121e-01,  5.6459e-02,\n",
       "                       3.3102e-01,  4.4782e-02,  1.5610e-01, -2.2526e-01,  6.8303e-02,\n",
       "                      -2.0179e-01, -1.9518e-01,  2.1296e-01, -4.3568e-01,  1.1925e-01,\n",
       "                       6.2413e-02,  8.9096e-02,  3.2550e-01, -2.9380e-02,  8.6485e-02,\n",
       "                       1.3629e-01, -2.9016e-01, -2.7445e-01, -3.0960e-01, -6.0889e-02,\n",
       "                      -5.6794e-02,  2.1900e-01, -1.2512e-03,  4.0566e-01, -4.0537e-01,\n",
       "                      -6.0136e-01, -1.7422e-01, -7.1549e-01, -3.2614e-02, -8.5478e-02,\n",
       "                      -2.3100e-01, -9.1810e-01, -6.1791e-02,  1.3999e-01,  2.8186e-01,\n",
       "                      -5.4611e-02, -6.6350e-02, -5.0397e-02,  3.8206e-01,  3.7839e-01,\n",
       "                       3.4493e-02, -2.1100e-01, -1.0143e-01,  2.0573e-01, -4.2642e-01,\n",
       "                      -2.4762e-01, -2.4102e-01,  6.0690e-02, -3.2306e-02, -5.3550e-02,\n",
       "                      -7.2446e-01,  2.2804e-02, -6.8294e-03, -2.7488e-01, -5.1908e-01,\n",
       "                      -4.5045e-02, -4.1890e-02, -2.2146e-01,  1.6638e-01, -2.6239e-01,\n",
       "                      -2.2276e-01, -1.7558e-01,  7.4842e-02,  5.6275e-02,  2.5991e-01,\n",
       "                      -3.7587e-02, -5.9472e-01, -9.0878e-03,  4.5406e-03, -2.0018e-01,\n",
       "                      -8.7271e-02, -6.0361e-02, -2.6818e-02, -1.2783e-01, -4.7172e-01,\n",
       "                      -4.9532e-02,  9.3877e-03, -2.4254e-01, -5.4999e-01, -1.8144e-01,\n",
       "                       1.7600e-01, -5.8138e-02, -9.4931e-02, -5.0127e-02, -4.9973e-02,\n",
       "                      -1.7717e-01,  3.4188e-02, -4.5878e-01, -1.5783e-01, -4.3395e-02,\n",
       "                      -1.5028e-01,  2.1028e-02,  6.7804e-02, -1.1270e-01, -4.3297e-01,\n",
       "                      -2.4953e-02, -3.3450e-01, -1.0887e-01, -4.4387e-02, -1.3994e-01,\n",
       "                      -3.6341e-02, -2.9594e-01, -2.1556e-02,  2.8448e-02, -5.5983e-01,\n",
       "                      -5.2901e-02, -1.3255e-01,  1.4301e-01, -1.8364e-01, -5.3769e-02,\n",
       "                      -1.7020e-01, -1.1749e-02, -4.0439e-02, -4.7513e-02, -1.1840e-01])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-3.0947e-01, -4.6246e-03,  9.1395e-03,  ...,  4.0362e-02,\n",
       "                       -2.7637e-01,  1.9534e-01],\n",
       "                      [ 9.4061e-02, -2.1254e-01, -1.8222e-02,  ..., -1.3263e-04,\n",
       "                       -2.7808e-01, -1.3196e-01],\n",
       "                      [-2.4463e-02,  1.3174e-02, -3.8276e-02,  ..., -4.3171e-02,\n",
       "                       -6.2846e-03, -6.0936e-02],\n",
       "                      ...,\n",
       "                      [-9.1937e-01,  3.9343e-01, -3.1904e-02,  ..., -2.3744e-02,\n",
       "                       -8.5860e-01, -4.4114e-01],\n",
       "                      [-6.7334e-02, -3.5695e-01, -1.7051e-02,  ..., -3.0704e-03,\n",
       "                       -5.3827e-01, -6.1609e-01],\n",
       "                      [ 3.9118e-01, -6.8230e-02, -9.1504e-03,  ...,  9.2789e-03,\n",
       "                       -2.1885e-01,  7.9839e-02]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0207, -0.4091, -0.1006,  0.1250,  0.1773, -0.0365, -0.2681, -0.4292,\n",
       "                      -0.1081,  0.9936,  0.2812, -0.2320, -0.0149, -0.0754,  0.0526,  0.3200,\n",
       "                      -0.6307,  0.0871, -0.2668,  0.0284, -0.0602, -0.0334, -0.6262, -0.0758,\n",
       "                       0.1175, -0.0812, -0.0357,  0.0102, -0.6815, -0.7593, -0.0183, -0.0806,\n",
       "                      -0.6248, -0.0504, -0.0392, -0.8565, -0.3640,  0.3623,  0.0536,  0.1709,\n",
       "                      -0.0906,  0.0232,  0.2974,  0.1260,  0.4710, -0.2667,  0.3906, -0.2506,\n",
       "                      -0.0363,  0.0103,  0.6877, -0.0587,  0.4812, -0.0874,  0.1429,  0.2529,\n",
       "                       0.0057,  0.2876, -1.0573, -0.0286,  0.1125,  0.6173,  0.2476, -0.3893,\n",
       "                       1.2904, -0.6611, -0.0365, -0.1543, -0.2466,  0.8773,  0.8697, -0.1295,\n",
       "                      -0.0528, -0.6451, -0.0229,  0.0161,  0.0642, -0.7597,  0.4608,  0.0133,\n",
       "                       0.1710,  0.4359, -0.8061,  0.5268, -0.3036, -0.3084,  0.3024,  0.0751,\n",
       "                       0.1777,  0.7186, -0.6452, -0.7350,  0.1441, -0.6206,  0.6845, -0.1083,\n",
       "                      -0.2267, -0.1224, -0.3324, -0.5282])),\n",
       "             ('sentiment_layer.weight',\n",
       "              tensor([[-8.6364e-01,  6.0131e-02,  5.7986e-02,  1.1563e-01,  1.4814e-01,\n",
       "                        9.6145e-03, -4.4816e-02, -4.6034e-01, -6.2639e-03, -1.2708e-01,\n",
       "                        4.4845e-02, -4.2902e-02,  8.0624e-02, -5.6267e-02, -1.8558e-01,\n",
       "                        3.3927e-01, -1.9839e-01, -3.9438e-01, -3.4554e-02,  3.3651e-02,\n",
       "                        5.4544e-02, -3.0038e-02, -5.2479e-03,  1.0052e-01, -1.8218e-01,\n",
       "                       -4.4875e-02, -8.5833e-03, -2.3686e-01, -3.7583e-01, -1.7221e-01,\n",
       "                        4.5355e-01, -6.0251e-02,  2.5608e-01,  2.8319e-02,  4.1749e-02,\n",
       "                       -3.4090e-01, -1.1551e+00, -2.6942e-01, -2.4829e-01, -5.2887e-01,\n",
       "                       -2.4318e-02, -1.0731e-02, -1.1661e-01,  3.7634e-02, -3.2735e-01,\n",
       "                        5.8834e-02, -1.5033e-01,  2.0435e-02, -2.4634e-01, -2.4293e-01,\n",
       "                        9.0671e-02, -3.3686e-02,  8.0088e-02,  4.8859e-02, -1.7572e-01,\n",
       "                        1.3046e-01, -7.0205e-01,  3.0154e-02, -2.1993e+00, -5.4251e-01,\n",
       "                       -1.4307e-01,  1.1453e-01,  1.1721e-01,  1.6607e-01,  1.5567e-01,\n",
       "                        8.8294e-02,  2.3626e-01, -1.4770e-02, -5.6077e-01,  6.8175e-02,\n",
       "                       -3.2202e-02,  3.3223e-02,  3.9163e-02, -2.0827e-01,  9.6304e-02,\n",
       "                       -8.3505e-02,  2.7281e-01, -4.2376e-01, -6.1071e-03,  8.8505e-02,\n",
       "                        6.7272e-02,  4.4245e-02,  7.5392e-02, -3.6420e-01, -1.4353e-02,\n",
       "                       -4.3741e-01,  1.2489e-02, -5.4663e-03,  8.6344e-02,  2.0670e-01,\n",
       "                        1.5168e-01, -1.7117e-01, -2.8476e-01,  2.1950e-01,  6.5903e-02,\n",
       "                       -8.5656e-02,  1.7040e-01, -3.2293e-01, -2.2116e-01, -4.9029e-01],\n",
       "                      [ 1.0715e-01,  3.3928e-02,  6.1340e-02, -1.3186e-01, -2.0494e-01,\n",
       "                       -3.9072e-02, -1.7619e-01, -3.3721e-02,  8.5288e-02,  2.8290e-02,\n",
       "                        5.7804e-02,  2.5695e-02, -6.0232e-02, -8.8295e-03,  7.8077e-02,\n",
       "                       -2.6464e-01, -8.4208e-02,  4.1719e-02,  1.2792e-01, -2.8599e-02,\n",
       "                        3.1304e-02, -1.4124e-02, -9.3621e-02,  7.6694e-02,  1.0792e-01,\n",
       "                        1.2175e-02,  1.7475e-03,  2.2389e-04,  6.4524e-02,  8.9747e-02,\n",
       "                       -8.8708e-02, -2.2931e-02, -1.5670e-01, -5.5918e-02, -5.2463e-02,\n",
       "                        1.7390e-02,  2.2958e-01,  5.9810e-02, -4.3578e-02,  3.3048e-01,\n",
       "                        8.6751e-03, -7.2816e-02, -8.7052e-02, -1.4360e-01,  8.4538e-02,\n",
       "                       -1.5542e-01,  2.1333e-02, -3.5650e-01,  1.4188e-01, -2.6817e-01,\n",
       "                       -2.1289e-02, -4.5139e-02, -1.9384e-01, -6.0975e-03, -5.7927e-02,\n",
       "                       -3.8603e-02,  1.4102e-01, -2.7150e-02, -1.7489e-02, -5.2853e-02,\n",
       "                        1.2849e-01, -2.5608e-01,  7.0412e-02, -1.9848e-01, -2.9266e-01,\n",
       "                       -2.6539e-01, -3.7231e-01, -1.9151e-02,  9.3867e-02, -1.8266e-01,\n",
       "                       -1.3425e-01,  3.9386e-02,  9.5080e-02, -1.3899e-01,  5.5987e-02,\n",
       "                       -1.7930e-02, -3.6870e-01,  2.3167e-01,  1.9290e-02, -2.1585e-01,\n",
       "                        3.0714e-02, -7.6007e-02,  2.5648e-02, -2.2333e-02,  1.5319e-02,\n",
       "                       -3.6239e-01, -2.6836e-02,  4.2038e-02,  1.0262e-01, -1.8479e-01,\n",
       "                       -8.9982e-02,  1.2615e-02, -1.7525e-02, -3.0685e-01, -1.7052e-02,\n",
       "                       -7.5504e-02, -2.3387e-01,  5.2561e-02, -5.1566e-02,  5.1889e-02],\n",
       "                      [ 9.0741e-02, -3.1068e-01,  8.5776e-03, -1.1789e-01,  2.0861e-02,\n",
       "                       -6.5843e-02, -8.1884e-02,  2.8853e-02, -4.7676e-01, -4.4892e-01,\n",
       "                       -3.7186e-01, -2.5502e-02, -1.2418e-02, -3.9295e-02,  2.8519e-02,\n",
       "                       -4.4648e-01, -9.3091e-03,  1.2848e-01, -9.5889e-01, -1.0184e-03,\n",
       "                       -8.4904e-02, -1.4841e+00, -2.7523e-01, -1.2596e-01, -4.1289e-02,\n",
       "                        9.5698e-03, -4.5459e-02,  3.1204e-03,  1.4599e-01, -6.8468e-01,\n",
       "                       -2.3710e-02,  7.6279e-03, -4.5238e-01,  1.8753e-04, -6.9535e-03,\n",
       "                       -1.5276e-02,  2.1903e-02,  1.3545e-01, -6.2718e-02, -2.9954e-01,\n",
       "                       -3.4958e-02, -6.6773e-02, -1.3838e-01,  7.3901e-02,  9.7995e-02,\n",
       "                       -2.8977e-01, -1.1999e-01, -1.0752e-01,  6.4723e-02,  1.8044e-01,\n",
       "                       -6.9834e-01, -6.7767e-02,  9.5795e-02, -6.3825e-02,  1.4731e-02,\n",
       "                       -2.2977e-01,  1.1281e-01,  6.6728e-02, -5.7762e-02,  2.9888e-02,\n",
       "                        4.8618e-02,  1.3673e-01, -6.7061e-01, -4.4402e-01,  1.8734e-01,\n",
       "                        2.6323e-01, -2.7797e-03, -3.6490e-02,  2.5266e-01,  3.8942e-02,\n",
       "                        1.9409e-01, -4.8466e-02, -6.2941e-01,  2.0885e-01,  1.5321e-01,\n",
       "                        5.8257e-02, -3.4361e-01, -2.9009e-01,  1.4912e-02,  1.0073e-01,\n",
       "                       -1.1967e-01, -7.6208e-02, -4.7750e-01,  6.8100e-02,  1.6804e-02,\n",
       "                        2.0962e-01,  4.4712e-02,  3.1701e-02, -9.5710e-01,  2.3990e-02,\n",
       "                       -3.6891e-01, -3.8732e-01,  6.3076e-02, -9.9496e-02, -1.5438e-01,\n",
       "                       -2.5554e-01, -6.2236e-01,  1.1370e-01,  2.5652e-02,  1.4405e-01]])),\n",
       "             ('sentiment_layer.bias', tensor([-0.0878, -0.0480, -0.0247])),\n",
       "             ('party_layer.weight',\n",
       "              tensor([[-2.1921e-01,  1.1058e-01,  3.4428e-02, -7.2456e-01,  9.9970e-02,\n",
       "                        3.1677e-02, -1.0861e+00,  2.8369e-01,  1.4406e-01, -3.4915e-01,\n",
       "                       -1.6401e-01, -3.5260e-01,  4.9283e-01,  7.4280e-02,  1.0610e-01,\n",
       "                       -8.7153e-02, -3.2515e-01,  2.3337e-01, -8.7824e-02,  4.2032e-01,\n",
       "                       -6.9043e-02,  1.8962e+00, -8.4992e-02, -3.8793e-02, -7.1862e-01,\n",
       "                        4.1422e-02,  4.3965e-02, -2.8349e-01, -7.5561e-01, -1.1338e-01,\n",
       "                        9.3753e-01, -4.6508e-02,  1.5643e-01, -3.4450e-04, -2.8263e-02,\n",
       "                        3.6790e-01,  5.5678e-01, -2.2125e-02,  1.9803e+00,  1.0463e-01,\n",
       "                        2.3480e-02, -1.2717e+00, -3.8437e-01, -7.6158e-01,  2.2056e-01,\n",
       "                        1.2754e-02,  4.9254e-02,  5.7533e-03, -9.4405e-02,  6.5331e-02,\n",
       "                       -1.1713e-01,  4.0966e-02, -5.4778e-02,  5.7991e-02,  1.5158e-02,\n",
       "                        9.0909e-01,  1.8419e-01, -4.2223e-02, -9.2132e+00, -3.4493e-01,\n",
       "                        8.9681e-01, -2.2891e-01,  9.2181e-02, -2.4963e-01,  2.6241e-01,\n",
       "                       -1.5622e+00,  1.2870e-01, -1.7913e-01, -1.3547e-01, -1.8731e-01,\n",
       "                        1.5907e-01, -2.4045e-02,  7.2728e-03,  9.8725e-01, -7.5795e-01,\n",
       "                        2.5212e-01, -4.7176e-02, -2.0299e-01, -3.6543e-01, -8.3187e-01,\n",
       "                       -2.6739e-03,  3.0262e-01,  2.8417e-01, -2.4222e-01,  1.4555e-01,\n",
       "                       -4.5464e-01, -2.3076e-01, -1.6690e+00, -2.2419e-01,  1.5985e-02,\n",
       "                       -1.0480e-01, -6.4212e-01,  1.7817e-01, -6.1354e-01,  1.1204e-02,\n",
       "                       -5.4656e-01,  3.3876e-01, -2.1904e-01, -1.0028e+00, -2.0736e+00],\n",
       "                      [-4.7619e-01,  5.5664e-01,  8.1642e-02,  1.1950e+00, -2.3077e-01,\n",
       "                       -2.1707e-02,  1.3951e+00,  8.1407e-02,  3.3071e-01,  6.5638e-03,\n",
       "                        1.7655e-01, -2.1571e-01,  7.0469e-01,  5.9684e-02, -7.1005e-01,\n",
       "                        2.9719e-01, -3.4118e-01,  3.0720e-01,  1.0170e+00,  1.0094e+00,\n",
       "                        5.7899e-02, -1.1707e+00,  7.4169e-02,  3.9209e-03,  6.4757e-01,\n",
       "                       -1.4410e-01, -1.0616e-01, -4.4787e-01,  2.3868e-01,  3.7286e-02,\n",
       "                        2.6335e-01, -2.9592e-02, -3.5552e-01, -1.2665e-01,  2.5192e-03,\n",
       "                       -9.4502e-01,  3.1361e-02, -2.9365e-01, -9.2798e-01, -3.9774e-01,\n",
       "                       -1.5053e-02, -8.4776e-01, -6.3471e-02,  3.1169e-01,  6.3570e-02,\n",
       "                       -7.3111e-02, -3.3420e-02,  4.1211e-01,  1.6003e-01, -7.3056e-02,\n",
       "                       -7.6940e-02, -4.5560e-02, -1.2794e-01, -9.3022e-02,  1.9615e-01,\n",
       "                        2.3414e-01,  1.0032e-01,  6.2693e-01, -6.0700e+00, -5.1933e-02,\n",
       "                        2.1267e-02, -7.5718e-02, -1.9702e-01, -2.1381e-01,  7.8983e-02,\n",
       "                       -8.9952e-01, -1.7916e-01, -4.5272e-02,  9.2005e-02, -5.7031e-02,\n",
       "                        5.4381e-01,  1.9081e-02, -2.5493e-02, -8.8519e-01, -8.4672e-01,\n",
       "                       -4.6977e-02,  5.1567e-02,  2.2474e-01, -3.5978e-01, -5.9466e-01,\n",
       "                       -3.9241e-02, -1.4799e+00, -3.7145e-01, -1.5178e-01,  3.9156e-01,\n",
       "                       -3.1531e-01, -1.3294e-01, -1.8603e+00, -1.4961e-01, -4.6975e-02,\n",
       "                       -2.6324e-01, -1.0610e-01,  7.6675e-02,  5.3845e-01,  4.7054e-02,\n",
       "                       -8.2247e-02,  1.0368e-01, -2.5555e-01, -1.3553e+00,  1.3761e-01],\n",
       "                      [-7.4838e-01,  6.4728e-02, -5.3998e-02, -1.6050e+00, -1.4115e+00,\n",
       "                        2.0144e-02, -1.6105e+00, -1.1915e+00, -1.0470e+00,  2.4401e-01,\n",
       "                        2.8948e-01, -2.4871e+00, -3.3824e-01, -1.4141e-01, -8.3878e-01,\n",
       "                       -1.6131e-01, -2.2765e-01, -4.4588e-01,  4.4428e-01, -3.5291e+00,\n",
       "                        2.5753e-02, -2.0647e+00, -1.0843e+00, -7.0184e-02, -1.0189e+00,\n",
       "                       -7.0924e-02, -5.3136e-01,  7.8455e-01, -2.5212e+00,  1.6470e-02,\n",
       "                       -9.4604e-01, -8.8308e-02, -7.2670e-01,  2.2169e-02,  1.4025e-02,\n",
       "                       -2.2144e+00, -2.1209e+00,  1.1265e-01, -1.9165e-01, -1.3695e+00,\n",
       "                        2.3855e-02, -1.4903e+00, -2.7092e+00, -8.5512e-01,  1.4011e-01,\n",
       "                       -1.4134e+00, -1.8071e+00, -9.4979e-01,  8.1501e-01,  4.7682e-01,\n",
       "                        4.4246e-03,  4.2369e-02,  4.0157e-01,  9.2830e-02, -6.2445e-02,\n",
       "                        2.5872e-01, -1.2431e-01, -3.0978e-01, -9.3656e+00,  1.1501e+00,\n",
       "                       -7.8129e-01,  4.6552e-01, -1.3804e-01, -1.1202e+00,  5.8459e-01,\n",
       "                       -8.4824e-02, -1.0068e+00, -1.7338e-01,  3.6794e-01,  2.3885e-01,\n",
       "                        6.2403e-01, -2.3588e-01, -6.0612e-02,  9.6506e-01, -1.4985e+00,\n",
       "                       -3.8162e+00, -1.4184e+00, -7.0622e-02, -2.4522e+00, -2.2816e+00,\n",
       "                        4.3187e-01,  9.8652e-01, -5.5801e-02, -1.1143e-01, -3.5471e-01,\n",
       "                       -4.9500e-01, -2.0792e+00, -2.8515e+00, -4.5453e-01, -3.2737e-02,\n",
       "                       -8.6702e-01, -8.4917e-01,  1.6714e-01, -1.3922e+00, -1.2409e-01,\n",
       "                       -1.0330e+00, -4.3770e-01,  2.7607e-01, -4.2155e-01,  1.1983e+00],\n",
       "                      [ 3.9086e-01, -5.6812e-01, -4.4521e-02, -1.2426e+00,  2.7079e-01,\n",
       "                       -8.2575e-02, -1.2657e+00, -1.9526e-01, -2.8960e-01,  1.0605e-01,\n",
       "                       -1.4917e-01,  3.1729e-01, -6.7090e-01,  2.0414e-02,  3.6254e-01,\n",
       "                       -1.2520e-01,  2.8233e-01, -1.2790e-01, -7.7350e-01, -5.6188e-01,\n",
       "                        4.0803e-02, -6.1561e-01, -3.6665e-02,  2.6840e-02, -6.6064e-01,\n",
       "                       -5.0279e-02, -1.0464e-01,  1.9471e-03, -3.6605e-02,  1.3967e-02,\n",
       "                       -6.6842e-01, -4.2108e-02,  5.5141e-02,  7.8895e-02,  4.4295e-02,\n",
       "                       -3.0346e-01,  1.7679e-01,  2.3372e-01, -2.2923e+00,  2.8784e-01,\n",
       "                        3.7934e-02,  8.5955e-01,  1.3341e-01, -2.5502e-01, -1.2877e-01,\n",
       "                        3.0019e-01,  1.8525e-03, -3.3103e-01, -9.9900e-02, -5.2020e-02,\n",
       "                        2.5481e-01,  7.9720e-02,  6.9139e-02, -4.9163e-02, -1.8115e-01,\n",
       "                       -6.3644e-01, -8.7389e-02, -5.7552e-01, -2.4283e+00,  5.2029e-02,\n",
       "                       -6.0981e-01,  2.7833e-03,  6.7206e-02,  1.6606e-01, -1.2953e-01,\n",
       "                        1.1666e+00,  1.2884e-02, -3.0782e-02,  1.1709e-01,  4.8845e-02,\n",
       "                       -3.4144e-01, -6.4108e-02,  8.2724e-02, -6.4596e-01,  9.0477e-01,\n",
       "                       -1.2598e-01,  4.1751e-03, -1.9319e-01,  4.2112e-01,  6.8371e-01,\n",
       "                       -9.9568e-03, -3.1295e-01,  9.9962e-03,  1.8852e-01, -1.2893e-01,\n",
       "                        4.5274e-01,  1.5343e-01,  1.7596e+00,  3.7918e-01,  3.3021e-02,\n",
       "                        2.9779e-01,  3.0842e-01, -7.2823e-02, -4.7947e-01, -3.8849e-02,\n",
       "                        1.6738e-01, -3.1185e-01,  1.0104e-01,  1.3042e+00, -9.7407e-01]])),\n",
       "             ('party_layer.bias',\n",
       "              tensor([-1.8063, -1.3520, -2.5069,  1.0625]))])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'twitter_sentiment_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60115, 15)\n",
      "(13260, 15)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_excel('./data/vala_processed.xlsx')\n",
    "print(df2.shape)\n",
    "df2 = df2.drop_duplicates(['CONTENT'])\n",
    "df2 = df2.reset_index(drop=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BN</th>\n",
       "      <th>PH</th>\n",
       "      <th>PAS</th>\n",
       "      <th>General</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>statement agong malaysia disaksikan panglima t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13256</th>\n",
       "      <td>suruhanjaya pilihan raya malaysia kenyataan me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13257</th>\n",
       "      <td>telah berlangsung sebentar tadi , lelongan jam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>muar - ketua pemuda parti pribumi bersatu mala...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13259</th>\n",
       "      <td>this pru14 ge14 is the right time to iss the s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 CONTENT  #hashtags  #urls  \\\n",
       "13255  statement agong malaysia disaksikan panglima t...          0      0   \n",
       "13256  suruhanjaya pilihan raya malaysia kenyataan me...          0      0   \n",
       "13257  telah berlangsung sebentar tadi , lelongan jam...          0      0   \n",
       "13258  muar - ketua pemuda parti pribumi bersatu mala...          0      0   \n",
       "13259  this pru14 ge14 is the right time to iss the s...          2      0   \n",
       "\n",
       "       #mentions  #word  #capital  #pos_emojis  #neg_emojis  #emojis  \\\n",
       "13255          0     38         0            0            0        0   \n",
       "13256          0     28        14            0            0        0   \n",
       "13257          0     30         2            0            0        0   \n",
       "13258          0     26         3            0            0        0   \n",
       "13259          0     36         4            1            0        1   \n",
       "\n",
       "       #exclaimation_question sentiment  BN  PH  PAS  General  sentiment_label  \n",
       "13255                       0  Negative   1   1    0        0                0  \n",
       "13256                       0  Negative   0   1    0        0                0  \n",
       "13257                       0  Negative   0   1    0        0                0  \n",
       "13258                       0  Positive   0   1    0        0                1  \n",
       "13259                       0  Negative   1   1    0        0                0  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_excel('./data/vala_processed.xlsx')\n",
    "df2['sentiment_label'] = df2['sentiment'].map(lambda x: sentiment_mapping[x])\n",
    "\n",
    "error_list2 = []\n",
    "error_index2 = []\n",
    "for i, row in df2.iterrows():\n",
    "#     print(i)\n",
    "    try:\n",
    "        content_split = row['CONTENT'].split()\n",
    "        for word in content_split:\n",
    "            word_vectors.wv[word]\n",
    "    except:\n",
    "        error_list2.append(word)\n",
    "        error_index2.append(i)\n",
    "        \n",
    "df2 = df2.drop(error_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = NeuralNet()\n",
    "sent_criterion = nn.CrossEntropyLoss()\n",
    "party_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)  \n",
    "\n",
    "# data_loaders = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = TwitterDataset(df=df2, scaler=scaler, training=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=64, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# net2.load_state_dict(torch.load('twitter_sentiment_model_all.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/201], Loss: 1.4005\n",
      "Epoch [1/50], Step [200/201], Loss: 1.3808\n",
      "Training Sentiment Accuracy: 52.243564818415116 %\n",
      "Training Party Accuracy: 85.7956314086914 %\n",
      "Epoch [2/50], Step [100/201], Loss: 1.3597\n",
      "Epoch [2/50], Step [200/201], Loss: 1.3608\n",
      "Training Sentiment Accuracy: 54.81763745236799 %\n",
      "Training Party Accuracy: 86.02494812011719 %\n",
      "Epoch [3/50], Step [100/201], Loss: 1.3538\n",
      "Epoch [3/50], Step [200/201], Loss: 1.3967\n",
      "Training Sentiment Accuracy: 54.78653083443503 %\n",
      "Training Party Accuracy: 86.2348403930664 %\n",
      "Epoch [4/50], Step [100/201], Loss: 1.3009\n",
      "Epoch [4/50], Step [200/201], Loss: 1.3500\n",
      "Training Sentiment Accuracy: 53.99331207714441 %\n",
      "Training Party Accuracy: 87.13075256347656 %\n",
      "Epoch [5/50], Step [100/201], Loss: 1.2628\n",
      "Epoch [5/50], Step [200/201], Loss: 1.3246\n",
      "Training Sentiment Accuracy: 53.99331207714441 %\n",
      "Training Party Accuracy: 87.4475326538086 %\n",
      "Epoch [6/50], Step [100/201], Loss: 1.2207\n",
      "Epoch [6/50], Step [200/201], Loss: 1.3406\n",
      "Training Sentiment Accuracy: 53.92332218679524 %\n",
      "Training Party Accuracy: 87.02192687988281 %\n",
      "Epoch [7/50], Step [100/201], Loss: 1.2244\n",
      "Epoch [7/50], Step [200/201], Loss: 1.3266\n",
      "Training Sentiment Accuracy: 54.52212458200482 %\n",
      "Training Party Accuracy: 87.19293975830078 %\n",
      "Epoch [8/50], Step [100/201], Loss: 1.2196\n",
      "Epoch [8/50], Step [200/201], Loss: 1.3225\n",
      "Training Sentiment Accuracy: 54.654327708219924 %\n",
      "Training Party Accuracy: 87.7196044921875 %\n",
      "Epoch [9/50], Step [100/201], Loss: 1.2014\n",
      "Epoch [9/50], Step [200/201], Loss: 1.2901\n",
      "Training Sentiment Accuracy: 55.61085620965861 %\n",
      "Training Party Accuracy: 88.20545959472656 %\n",
      "Epoch [10/50], Step [100/201], Loss: 1.2021\n",
      "Epoch [10/50], Step [200/201], Loss: 1.2625\n",
      "Training Sentiment Accuracy: 56.100785442102804 %\n",
      "Training Party Accuracy: 88.59608459472656 %\n",
      "Epoch [11/50], Step [100/201], Loss: 1.1997\n",
      "Epoch [11/50], Step [200/201], Loss: 1.2308\n",
      "Training Sentiment Accuracy: 57.85830935531534 %\n",
      "Training Party Accuracy: 88.91674041748047 %\n",
      "Epoch [12/50], Step [100/201], Loss: 1.1772\n",
      "Epoch [12/50], Step [200/201], Loss: 1.1879\n",
      "Training Sentiment Accuracy: 59.04036083676802 %\n",
      "Training Party Accuracy: 89.2821044921875 %\n",
      "Epoch [13/50], Step [100/201], Loss: 1.1577\n",
      "Epoch [13/50], Step [200/201], Loss: 1.1630\n",
      "Training Sentiment Accuracy: 60.01244264717319 %\n",
      "Training Party Accuracy: 89.4492416381836 %\n",
      "Epoch [14/50], Step [100/201], Loss: 1.1261\n",
      "Epoch [14/50], Step [200/201], Loss: 1.1328\n",
      "Training Sentiment Accuracy: 61.62998677968738 %\n",
      "Training Party Accuracy: 89.78739166259766 %\n",
      "Epoch [15/50], Step [100/201], Loss: 1.0921\n",
      "Epoch [15/50], Step [200/201], Loss: 1.1174\n",
      "Training Sentiment Accuracy: 62.3687689555953 %\n",
      "Training Party Accuracy: 89.82237243652344 %\n",
      "Epoch [16/50], Step [100/201], Loss: 1.0684\n",
      "Epoch [16/50], Step [200/201], Loss: 1.1058\n",
      "Training Sentiment Accuracy: 63.65969359981336 %\n",
      "Training Party Accuracy: 90.0342025756836 %\n",
      "Epoch [17/50], Step [100/201], Loss: 1.0108\n",
      "Epoch [17/50], Step [200/201], Loss: 1.0853\n",
      "Training Sentiment Accuracy: 64.71731860953417 %\n",
      "Training Party Accuracy: 90.36846923828125 %\n",
      "Epoch [18/50], Step [100/201], Loss: 0.9322\n",
      "Epoch [18/50], Step [200/201], Loss: 1.0705\n",
      "Training Sentiment Accuracy: 65.74383700132204 %\n",
      "Training Party Accuracy: 90.52977752685547 %\n",
      "Epoch [19/50], Step [100/201], Loss: 0.9239\n",
      "Epoch [19/50], Step [200/201], Loss: 1.0644\n",
      "Training Sentiment Accuracy: 66.74702542966016 %\n",
      "Training Party Accuracy: 90.72022247314453 %\n",
      "Epoch [20/50], Step [100/201], Loss: 0.9009\n",
      "Epoch [20/50], Step [200/201], Loss: 1.0263\n",
      "Training Sentiment Accuracy: 68.10793996422738 %\n",
      "Training Party Accuracy: 90.88542175292969 %\n",
      "Epoch [21/50], Step [100/201], Loss: 0.8220\n",
      "Epoch [21/50], Step [200/201], Loss: 0.9637\n",
      "Training Sentiment Accuracy: 69.09557508359903 %\n",
      "Training Party Accuracy: 91.10113525390625 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-481-3e2585862185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dlenv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    party_accuracy = 0\n",
    "    for i, (features, sentLabel, partyLabel) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        features = features.float()\n",
    "        partyLabel = partyLabel.type(torch.FloatTensor)\n",
    "\n",
    "        # Forward pass\n",
    "        output_sent, output_party = net2(features)\n",
    "\n",
    "        sent_loss = sent_criterion(output_sent, sentLabel)\n",
    "        party_loss = party_criterion(output_party, partyLabel)\n",
    "#                 print((output_party.round() == partyLabel).type(torch.FloatTensor).sum()/(32*4))\n",
    "        loss = sent_loss + party_loss\n",
    "    \n",
    "        # calculate sentiment accuracy\n",
    "        _, predicted = torch.max(output_sent.data, 1)\n",
    "        total += sentLabel.size(0)\n",
    "        correct += (predicted == sentLabel).sum().item()\n",
    "        \n",
    "#         print((output_party.round() == partyLabel).type(torch.FloatTensor).sum()/(64*4))\n",
    "        party_accuracy += (output_party.round() == partyLabel).type(torch.FloatTensor).sum()/(64*4)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        \n",
    "    print('Training Sentiment Accuracy: {} %'.format(100 * correct / total))\n",
    "    print('Training Party Accuracy: {} %'.format(100 * (party_accuracy/len(train_loader))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net2.state_dict(), 'twitter_sentiment_model_all.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_test = pd.read_excel('./data/issues_processed_v2.xlsx')\n",
    "df_test.columns = ['CONTENT', '#hashtags', '#urls', '#mentions', '#word', '#capital',\n",
    "       '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question',\n",
    "       'keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perdaftaran bantuan sara hidup ( bsh ) akan di...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  #hashtags  #urls  \\\n",
       "0  perdaftaran bantuan sara hidup ( bsh ) akan di...          3      0   \n",
       "1  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "2  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "3  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "4  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "\n",
       "   #mentions  #word  #capital  #pos_emojis  #neg_emojis  #emojis  \\\n",
       "0          0     18         1            0            0        0   \n",
       "1          0     18         2            0            0        0   \n",
       "2          0     18         2            0            0        0   \n",
       "3          0     18         2            0            0        0   \n",
       "4          0     18         2            0            0        0   \n",
       "\n",
       "   #exclaimation_question     keyword  \n",
       "0                       0  Budget2019  \n",
       "1                       0  Budget2019  \n",
       "2                       0  Budget2019  \n",
       "3                       0  Budget2019  \n",
       "4                       0  Budget2019  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list_test = []\n",
    "error_index_test = []\n",
    "for i, row in df_test.iterrows():\n",
    "#     print(i)\n",
    "    try:\n",
    "        content_split = row['CONTENT'].split()\n",
    "        for word in content_split:\n",
    "            word_vectors.wv[word]\n",
    "    except:\n",
    "        error_list_test.append(word)\n",
    "        error_index_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(error_index_test)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TwitterDataset(df=df_test, scaler=scaler, training=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0143, -0.0067,  0.0039,  ..., -0.0399, -0.1628, -0.3705],\n",
       "        [ 0.0079, -0.0030,  0.0018,  ..., -0.0399, -0.1628, -0.3705],\n",
       "        [ 0.0079, -0.0030,  0.0018,  ..., -0.0399, -0.1628, -0.3705],\n",
       "        ...,\n",
       "        [ 0.0079, -0.0030,  0.0018,  ..., -0.0399, -0.1628, -0.3705],\n",
       "        [ 0.0082, -0.0029,  0.0019,  ..., -0.0399, -0.1628, -0.3705],\n",
       "        [ 0.0143, -0.0067,  0.0039,  ..., -0.0399, -0.1628, -0.3705]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sent_list = []\n",
    "predicted_party_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (features) in enumerate(test_loader):  \n",
    "        features = features.float()\n",
    "        partyLabel = partyLabel.type(torch.FloatTensor)\n",
    "\n",
    "        output_sent, output_party = net2(features)\n",
    "\n",
    "        _, predicted_sent = torch.max(output_sent.data, 1)\n",
    "        predicted_party = output_party.round()\n",
    "        \n",
    "        predicted_party_list+=predicted_party.numpy().tolist()\n",
    "        predicted_sent_list+=predicted_sent.numpy().tolist()\n",
    "#         print(predicted_party_list)\n",
    "        \n",
    "#         predicted_sent_list.append(predicted_sent)\n",
    "#         predicted_party_list.append(predicted_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BN</th>\n",
       "      <th>PH</th>\n",
       "      <th>PAS</th>\n",
       "      <th>General</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BN  PH  PAS  General\n",
       "0   0   0    0        1\n",
       "1   0   0    0        1\n",
       "2   0   0    0        1\n",
       "3   0   0    0        1\n",
       "4   0   0    0        1"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_party = pd.DataFrame(np.vstack(predicted_party_list).astype('int'))\n",
    "df_pred_party.columns = ['BN','PH','PAS','General']\n",
    "df_pred_party.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          2\n",
       "1          2\n",
       "2          2\n",
       "3          2\n",
       "4          2"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_sent = pd.DataFrame(np.vstack(predicted_sent_list).astype('int'))\n",
    "df_pred_sent.columns = ['sentiment']\n",
    "df_pred_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predicted = pd.concat([df_test, df_pred_sent, df_pred_party], sort=False, axis=1)\n",
    "df_test_predicted['sentiment'] = df_test_predicted['sentiment'].map(lambda x: sentiment_mapping_reverse[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "      <th>keyword</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>BN</th>\n",
       "      <th>PH</th>\n",
       "      <th>PAS</th>\n",
       "      <th>General</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perdaftaran bantuan sara hidup ( bsh ) akan di...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt perdaftaran bantuan sara hidup ( bsh ) akan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Budget2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  #hashtags  #urls  \\\n",
       "0  perdaftaran bantuan sara hidup ( bsh ) akan di...          3      0   \n",
       "1  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "2  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "3  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "4  rt perdaftaran bantuan sara hidup ( bsh ) akan...          2      0   \n",
       "\n",
       "   #mentions  #word  #capital  #pos_emojis  #neg_emojis  #emojis  \\\n",
       "0          0     18         1            0            0        0   \n",
       "1          0     18         2            0            0        0   \n",
       "2          0     18         2            0            0        0   \n",
       "3          0     18         2            0            0        0   \n",
       "4          0     18         2            0            0        0   \n",
       "\n",
       "   #exclaimation_question     keyword sentiment  BN  PH  PAS  General  \n",
       "0                       0  Budget2019   Neutral   0   0    0        1  \n",
       "1                       0  Budget2019   Neutral   0   0    0        1  \n",
       "2                       0  Budget2019   Neutral   0   0    0        1  \n",
       "3                       0  Budget2019   Neutral   0   0    0        1  \n",
       "4                       0  Budget2019   Neutral   0   0    0        1  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_predicted.to_excel(\"./data/issues_processed_v2_prediction.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_BR1M_1202.xlsx')\n",
    "df2 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_Budget2019_1202.xlsx')\n",
    "df3 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_ICERD_1202.xlsx')\n",
    "df4 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_PRKCameronHighlands_1202.xlsx')\n",
    "df5 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_PRU14_1202.xlsx')\n",
    "df6 = pd.read_excel('./data/Tweet sentiment/TAGGED_normalised_SST_1202.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2, df3, df4, df5, df6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n",
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n",
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n",
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n",
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n",
      "['full_text', 'text4', 'Sentiment', 'Remark', 'Tagged by', '#hashtags', '#urls', '#mentions', '#word', '#capital', '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question']\n"
     ]
    }
   ],
   "source": [
    "for i in df_list:\n",
    "    print(i.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5407, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text4</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Tagged by</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>Tun M memulakan ucapan di Kuala Kedah. https:/...</td>\n",
       "      <td>tun memulakan ucapan di kuala kedah &lt;url&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Dulu kita miskin. Semasa kita berjuang masa na...</td>\n",
       "      <td>dulu kita miskin semasa kita berjuang masa nak...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Najib sudah mengikat negara China. Kita baik t...</td>\n",
       "      <td>najib sudah mengikat negara china kita baik ta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>RT @SumishaCNA: Opposition needs to form a coa...</td>\n",
       "      <td>opposition needs to form coalition to remove p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>10. Diperingkat akar umbi dan juga segelintir ...</td>\n",
       "      <td>diperingkat akar umbi dan juga segelintir pemi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              full_text  \\\n",
       "2443  Tun M memulakan ucapan di Kuala Kedah. https:/...   \n",
       "2444  Dulu kita miskin. Semasa kita berjuang masa na...   \n",
       "2445  Najib sudah mengikat negara China. Kita baik t...   \n",
       "2446  RT @SumishaCNA: Opposition needs to form a coa...   \n",
       "2447  10. Diperingkat akar umbi dan juga segelintir ...   \n",
       "\n",
       "                                                  text4 Sentiment Remark  \\\n",
       "2443          tun memulakan ucapan di kuala kedah <url>       NaN    NaN   \n",
       "2444  dulu kita miskin semasa kita berjuang masa nak...       NaN    NaN   \n",
       "2445  najib sudah mengikat negara china kita baik ta...       NaN    NaN   \n",
       "2446  opposition needs to form coalition to remove p...       NaN    NaN   \n",
       "2447  diperingkat akar umbi dan juga segelintir pemi...       NaN    NaN   \n",
       "\n",
       "     Tagged by  #hashtags  #urls  #mentions  #word  #capital  #pos_emojis  \\\n",
       "2443       NaN          0      0          0      9         1            0   \n",
       "2444       NaN          0      0          0     27         1            0   \n",
       "2445       NaN          0      0          0     27         1            0   \n",
       "2446       NaN          0      0          1     19         3            0   \n",
       "2447       NaN          0      0          0     24         2            0   \n",
       "\n",
       "      #neg_emojis  #emojis  #exclaimation_question  \n",
       "2443            0        0                       0  \n",
       "2444            0        0                       0  \n",
       "2445            0        0                       1  \n",
       "2446            0        0                       0  \n",
       "2447            0        0                       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neu', 'pos', nan, 'positive'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()\n",
    "# df['Tagged by'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['Tagged by']=='akmal')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Sentiment']=='new','Sentiment'] = 'neu'\n",
    "df.loc[df['Sentiment']=='neu/pos','Sentiment'] = 'pos'\n",
    "df.loc[df['Sentiment']=='neu/positive', 'Sentiment'] = 'pos'\n",
    "df.loc[df['Sentiment']=='neu/neg', 'Sentiment'] = 'pos' \n",
    "df.loc[df['Sentiment']=='positive', 'Sentiment'] = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/miniconda3/envs/dlenv/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text4</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Remark</th>\n",
       "      <th>Tagged by</th>\n",
       "      <th>#hashtags</th>\n",
       "      <th>#urls</th>\n",
       "      <th>#mentions</th>\n",
       "      <th>#word</th>\n",
       "      <th>#capital</th>\n",
       "      <th>#pos_emojis</th>\n",
       "      <th>#neg_emojis</th>\n",
       "      <th>#emojis</th>\n",
       "      <th>#exclaimation_question</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @monamalaysia: @shonzu11 Jangan merendahkan...</td>\n",
       "      <td>jangan merendahkan kebolehan pm memerintah den...</td>\n",
       "      <td>neg</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>Keng Hooi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Nasionalis_: Jika BR1M itu ibarat candu, m...</td>\n",
       "      <td>jika br1m itu ibarat candu maka bsh bantuan sa...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keng Hooi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @myintifada: Look at ridiculously IDIOT PH ...</td>\n",
       "      <td>look at ridiculously idiot ph government use o...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keng Hooi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sokongan masyarakat diperlukan utk membantu pi...</td>\n",
       "      <td>sokongan masyarakat diperlukan untuk membantu ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keng Hooi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BetterNation3: @Nazgul71028348 @spender_bi...</td>\n",
       "      <td>sekiranya br1m diibaratkan sebagai candu adaka...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keng Hooi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  RT @monamalaysia: @shonzu11 Jangan merendahkan...   \n",
       "1  RT @Nasionalis_: Jika BR1M itu ibarat candu, m...   \n",
       "2  RT @myintifada: Look at ridiculously IDIOT PH ...   \n",
       "3  Sokongan masyarakat diperlukan utk membantu pi...   \n",
       "4  RT @BetterNation3: @Nazgul71028348 @spender_bi...   \n",
       "\n",
       "                                               text4 Sentiment   Remark  \\\n",
       "0  jangan merendahkan kebolehan pm memerintah den...       neg  sarcasm   \n",
       "1  jika br1m itu ibarat candu maka bsh bantuan sa...       neg      NaN   \n",
       "2  look at ridiculously idiot ph government use o...       neg      NaN   \n",
       "3  sokongan masyarakat diperlukan untuk membantu ...       neu      NaN   \n",
       "4  sekiranya br1m diibaratkan sebagai candu adaka...       neg      NaN   \n",
       "\n",
       "   Tagged by  #hashtags  #urls  #mentions  #word  #capital  #pos_emojis  \\\n",
       "0  Keng Hooi          0      0          2     54         2            0   \n",
       "1  Keng Hooi          0      0          1     23         2            0   \n",
       "2  Keng Hooi          0      0          1     64         5            0   \n",
       "3  Keng Hooi          0      0          0     18         2            0   \n",
       "4  Keng Hooi          0      0         10     72         1            0   \n",
       "\n",
       "   #neg_emojis  #emojis  #exclaimation_question  sentiment_label  \n",
       "0            0        0                       0                0  \n",
       "1            0        0                       1                0  \n",
       "2            0        0                       1                0  \n",
       "3            0        0                       0                2  \n",
       "4            0        0                       0                0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = df[~df['Sentiment'].isna()]\n",
    "dff['sentiment_label'] = dff['Sentiment'].map(lambda x: sentiment_mapping2[x])\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list2 = []\n",
    "error_index2 = []\n",
    "for i, row in dff.iterrows():\n",
    "    try:\n",
    "        content_split = row['text4'].split()\n",
    "        for word in content_split:\n",
    "            word_vectors.wv[word]\n",
    "    except:\n",
    "        error_list2.append(word)\n",
    "        error_index2.append(i)\n",
    "        \n",
    "dff2 = dff.drop(error_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(data.Dataset):\n",
    "    def __init__(self, df, scaler, training=True, normalize=True):\n",
    "        self.data = df\n",
    "        self.scaler = scaler\n",
    "        self.tweet = self.data[['text4']]\n",
    "        self.training = training\n",
    "        self.metadata = self.data[['#hashtags','#urls','#mentions','#word','#capital','#pos_emojis','#neg_emojis','#emojis','#exclaimation_question']]\n",
    "        \n",
    "        if normalize:\n",
    "            self.metadata = scaler.fit_transform(self.metadata)\n",
    "        else:\n",
    "            self.metadata = scaler.transform(self.metadata)\n",
    "            \n",
    "        if training:\n",
    "#             self.party_label = self.data[['PH','BN','PAS','General']]\n",
    "            self.sentiment_label = self.data[['sentiment_label']]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def prepareVector(self, sentence):\n",
    "        sentence = sentence.split()\n",
    "        featureVec = np.zeros(300)\n",
    "        nwords = 0\n",
    "\n",
    "        for word in sentence:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,word_vectors.wv[word])\n",
    "\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wordFeature = self.prepareVector(self.tweet.iloc[index].values[0])\n",
    "        metadataFeature = self.metadata[index]\n",
    "        \n",
    "        feature = np.concatenate([wordFeature, metadataFeature])\n",
    "        \n",
    "        if self.training:\n",
    "            sentLabel = self.sentiment_label.iloc[index].values\n",
    "#             partyLabel = self.party_label.iloc[index].values\n",
    "            \n",
    "            return feature, sentLabel[0]\n",
    "        else:\n",
    "            return feature\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(309, 1000) \n",
    "        self.fc2 = nn.Linear(1000, 500) \n",
    "        self.fc3 = nn.Linear(500, 100)\n",
    "        self.sentiment_layer = nn.Linear(100, 3)\n",
    "        self.party_layer = nn.Linear(100, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        sentiment_output = self.sentiment_layer(x)\n",
    "        party_output = torch.sigmoid(self.party_layer(x))\n",
    "        return sentiment_output, party_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(dff2, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = TwitterDataset(df=train_df, scaler=scaler, training=True, normalize=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, num_workers=4)\n",
    "\n",
    "val_dataset = TwitterDataset(df=val_df, scaler= scaler, training=True, normalize=False)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = NeuralNet()\n",
    "sent_criterion = nn.CrossEntropyLoss()\n",
    "party_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)  \n",
    "\n",
    "data_loaders = {'train': train_loader, 'val': val_loader}# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Sentiment Accuracy: 52.12765957446808 %\n",
      "Validation Sentiment Accuracy: 55.851063829787236 %\n",
      "Validation Sentiment Accuracy: 56.91489361702128 %\n",
      "Validation Sentiment Accuracy: 60.1063829787234 %\n",
      "Validation Sentiment Accuracy: 60.1063829787234 %\n",
      "Validation Sentiment Accuracy: 64.8936170212766 %\n",
      "Validation Sentiment Accuracy: 63.297872340425535 %\n",
      "Validation Sentiment Accuracy: 66.48936170212765 %\n",
      "Validation Sentiment Accuracy: 65.95744680851064 %\n",
      "Validation Sentiment Accuracy: 64.8936170212766 %\n",
      "Validation Sentiment Accuracy: 61.702127659574465 %\n",
      "Validation Sentiment Accuracy: 61.170212765957444 %\n",
      "Validation Sentiment Accuracy: 60.1063829787234 %\n",
      "Validation Sentiment Accuracy: 60.638297872340424 %\n",
      "Validation Sentiment Accuracy: 62.234042553191486 %\n",
      "Validation Sentiment Accuracy: 60.638297872340424 %\n",
      "Validation Sentiment Accuracy: 59.04255319148936 %\n",
      "Validation Sentiment Accuracy: 61.702127659574465 %\n",
      "Validation Sentiment Accuracy: 63.297872340425535 %\n",
      "Validation Sentiment Accuracy: 63.829787234042556 %\n",
      "Validation Sentiment Accuracy: 67.02127659574468 %\n",
      "Validation Sentiment Accuracy: 66.48936170212765 %\n",
      "Validation Sentiment Accuracy: 62.765957446808514 %\n",
      "Validation Sentiment Accuracy: 67.55319148936171 %\n",
      "Validation Sentiment Accuracy: 65.95744680851064 %\n",
      "Validation Sentiment Accuracy: 66.48936170212765 %\n",
      "Validation Sentiment Accuracy: 64.36170212765957 %\n",
      "Validation Sentiment Accuracy: 61.702127659574465 %\n",
      "Validation Sentiment Accuracy: 63.829787234042556 %\n",
      "Validation Sentiment Accuracy: 63.297872340425535 %\n",
      "Validation Sentiment Accuracy: 67.02127659574468 %\n",
      "Validation Sentiment Accuracy: 64.36170212765957 %\n",
      "Validation Sentiment Accuracy: 62.234042553191486 %\n",
      "Validation Sentiment Accuracy: 63.829787234042556 %\n",
      "Validation Sentiment Accuracy: 64.36170212765957 %\n",
      "Validation Sentiment Accuracy: 59.04255319148936 %\n",
      "Validation Sentiment Accuracy: 58.51063829787234 %\n",
      "Validation Sentiment Accuracy: 64.36170212765957 %\n",
      "Validation Sentiment Accuracy: 67.02127659574468 %\n",
      "Validation Sentiment Accuracy: 67.55319148936171 %\n",
      "Validation Sentiment Accuracy: 68.08510638297872 %\n",
      "Validation Sentiment Accuracy: 68.08510638297872 %\n",
      "Validation Sentiment Accuracy: 67.02127659574468 %\n",
      "Validation Sentiment Accuracy: 67.55319148936171 %\n",
      "Validation Sentiment Accuracy: 66.48936170212765 %\n",
      "Validation Sentiment Accuracy: 68.08510638297872 %\n",
      "Validation Sentiment Accuracy: 67.02127659574468 %\n",
      "Validation Sentiment Accuracy: 65.95744680851064 %\n",
      "Validation Sentiment Accuracy: 65.42553191489361 %\n",
      "Validation Sentiment Accuracy: 66.48936170212765 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs=50\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            for i, (features, sentLabel) in enumerate(data_loaders[phase]):  \n",
    "                # Move tensors to the configured device\n",
    "                features = features.float()\n",
    "\n",
    "                # Forward pass\n",
    "                output_sent, output_party = net2(features)\n",
    "\n",
    "                sent_loss = sent_criterion(output_sent, sentLabel)\n",
    "                loss = sent_loss \n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                party_accuracy = 0\n",
    "                for i, (features, sentLabel) in enumerate(data_loaders[phase]):  \n",
    "                    features = features.float()\n",
    "                    \n",
    "                    output_sent, output_party = net2(features)\n",
    "                    \n",
    "                    # calculate sentiment accuracy\n",
    "                    _, predicted = torch.max(output_sent.data, 1)\n",
    "                    total += sentLabel.size(0)\n",
    "                    correct += (predicted == sentLabel).sum().item()\n",
    "                    \n",
    "                    \n",
    "                print('Validation Sentiment Accuracy: {} %'.format(100 * correct / total))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "test_df = pd.read_excel('./data/issues_processed_v2_prediction.xlsx')\n",
    "test_df.columns = ['text4', '#hashtags', '#urls', '#mentions', '#word', '#capital',\n",
    "       '#pos_emojis', '#neg_emojis', '#emojis', '#exclaimation_question',\n",
    "       'keyword', 'sentiment', 'BN', 'PH', 'PAS', 'General']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TwitterDataset(df=test_df, scaler=scaler, training=False, normalize=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.43284910e-02, -6.68050930e-03,  3.92305043e-03,  2.90000593e-03,\n",
       "        1.50832787e-02, -8.47821523e-02,  1.47555937e-02, -9.06560340e-03,\n",
       "       -3.63997864e-03, -1.88522477e-02,  8.24395494e-03, -2.51325851e-03,\n",
       "        2.87103008e-02,  1.82489220e-02, -1.65291102e-02,  8.18374134e-03,\n",
       "       -6.53118748e-03,  4.59973937e-03,  9.18282275e-03, -9.32116907e-03,\n",
       "        2.32980924e-03, -2.59659115e-03,  8.41681514e-03, -5.76652131e-03,\n",
       "        1.56107316e-02,  1.50073552e-02, -2.38437614e-02, -7.81121353e-03,\n",
       "        2.32750522e-02,  2.00437118e-03, -5.41383905e-03, -7.58255519e-03,\n",
       "        7.84398056e-03,  2.22738192e-02, -6.73363723e-03, -3.06394815e-03,\n",
       "       -1.56717141e-02,  6.70031434e-03,  1.26784304e-02, -2.57465256e-03,\n",
       "       -9.64734219e-03, -4.74523512e-03, -8.41431072e-03,  1.14093381e-02,\n",
       "       -6.66123070e-04,  1.19591735e-02,  1.06282565e-02, -9.07487262e-03,\n",
       "        1.07270383e-02, -1.42936123e-02,  9.69155639e-03, -5.23357181e-04,\n",
       "        2.21079667e-02, -6.56554327e-03, -2.75908563e-03, -2.13552595e-02,\n",
       "       -1.28395646e-02,  1.16586748e-02,  3.35008191e-02, -4.94618551e-03,\n",
       "        2.29642825e-03, -5.12097534e-04, -1.22679596e-02, -8.18272879e-04,\n",
       "        1.05756995e-02, -6.78560021e-03,  5.35591968e-03,  7.42731282e-03,\n",
       "        1.21953423e-02,  1.20095904e-02,  4.47934447e-03,  2.14170991e-03,\n",
       "        1.72932775e-02, -6.28752349e-03, -7.09343551e-03, -1.69716957e-02,\n",
       "       -8.66041918e-03,  3.98112820e-03,  6.23337116e-03,  1.64634274e-02,\n",
       "       -9.61483703e-03,  6.20627843e-03, -1.01424780e-02,  9.86580848e-04,\n",
       "       -1.44465731e-02, -2.09768306e-02,  4.11415960e-03,  3.20589211e-03,\n",
       "        4.52418297e-03, -2.56282728e-03,  8.43018653e-03,  2.13438911e-03,\n",
       "        1.93773284e-03,  2.17679995e-02,  6.82839869e-03,  1.70193239e-02,\n",
       "       -1.80677457e-02, -8.46327250e-03,  7.23918804e-03,  5.67629547e-03,\n",
       "        9.09679456e-03, -2.82481649e-02, -5.35991993e-03,  2.70505270e-03,\n",
       "       -4.16989589e-02, -5.69630998e-03, -1.10169632e-02,  5.62054291e-03,\n",
       "       -2.88559840e-02, -1.00856084e-02,  1.00754433e-02,  3.99311799e-03,\n",
       "        3.63062596e-03,  2.26832593e-03, -3.79604793e-03, -9.51001287e-03,\n",
       "       -2.57293502e-03, -1.13882340e-02,  1.06210350e-02,  3.15734572e-02,\n",
       "       -1.41109828e-02, -1.55357255e-03, -9.46904816e-03,  5.08426748e-03,\n",
       "        1.07847125e-03,  4.35901023e-04,  1.49131647e-02,  3.44907569e-03,\n",
       "       -1.03499298e-02, -9.92153289e-03, -3.29274072e-02, -1.49012905e-02,\n",
       "       -3.92344712e-02,  7.08489877e-03,  3.24882316e-02,  9.71145602e-04,\n",
       "       -6.59323490e-04,  1.60402398e-02,  2.23919908e-03,  1.60046417e-05,\n",
       "       -4.15121425e-03, -1.50348703e-02, -1.71992979e-03, -9.43275853e-03,\n",
       "       -1.16769658e-02,  2.07029869e-02,  1.38104704e-02, -3.60558369e-03,\n",
       "       -2.60950243e-03, -4.09349762e-03,  2.11227599e-03,  8.59498309e-04,\n",
       "       -5.07671232e-03, -7.24502606e-06,  1.46063584e-02,  2.01344925e-02,\n",
       "       -7.15725969e-03, -2.66737668e-03, -9.32322189e-05,  1.30425448e-02,\n",
       "        7.03941754e-03,  4.29728832e-03,  2.24275358e-03, -4.13397755e-03,\n",
       "       -1.43935089e-02, -5.80123155e-03,  4.26466319e-03, -1.83759787e-04,\n",
       "        1.43061465e-02, -9.01859527e-04, -1.53230350e-03,  4.78388879e-03,\n",
       "       -4.40751861e-03,  9.84481557e-03,  1.52993041e-02, -8.69168217e-03,\n",
       "        3.16075305e-02,  1.62430683e-02, -9.73859641e-03,  1.95490108e-02,\n",
       "        4.55179705e-03,  3.42048604e-03, -1.89474286e-03, -1.58775232e-02,\n",
       "        5.94543761e-03,  1.47392115e-02, -8.23937417e-03,  8.50272653e-03,\n",
       "        3.22726531e-02, -1.72692493e-02, -2.37728714e-04,  1.48506106e-02,\n",
       "        3.66455525e-02,  2.94146281e-02,  2.91056769e-02, -1.63736543e-02,\n",
       "        3.46675157e-03, -1.93929214e-03,  1.04260686e-03,  4.37693593e-03,\n",
       "       -2.91873029e-02, -8.25827907e-03,  1.16385895e-02,  2.53060755e-03,\n",
       "       -1.58234467e-02,  1.37602650e-02,  8.30007940e-03, -1.76628051e-03,\n",
       "        4.38616567e-03,  1.66345695e-02,  6.83559549e-03, -6.43449151e-03,\n",
       "       -3.34374486e-04,  9.31311112e-03, -7.57997466e-04, -4.36722552e-03,\n",
       "       -4.10620441e-03,  1.31573259e-02, -6.75739287e-04,  4.67344299e-03,\n",
       "       -9.27837020e-05, -4.66322211e-03,  1.54820129e-03,  1.96397718e-03,\n",
       "        2.57127025e-02, -8.61011690e-04,  4.50606876e-03,  2.20853370e-03,\n",
       "        1.12027274e-02, -7.45257307e-03, -8.90252844e-03, -6.02479654e-03,\n",
       "       -4.43537188e-03, -4.01057669e-03,  2.23070472e-02,  9.08679818e-03,\n",
       "       -2.76632165e-03,  8.37873156e-03, -6.46215659e-03, -4.83445982e-03,\n",
       "        2.17481619e-02, -1.30937730e-02,  9.31219332e-03, -1.02866438e-02,\n",
       "       -9.82012250e-04,  5.74539766e-03, -9.54937838e-03, -4.98255919e-03,\n",
       "        1.46614766e-02, -1.44069505e-02,  1.31149124e-02, -7.82684288e-04,\n",
       "        7.46675501e-04, -1.69199152e-02, -1.01498097e-02, -8.80908241e-03,\n",
       "        1.81218539e-04, -1.40322224e-02,  1.16513382e-02,  6.82922514e-03,\n",
       "       -5.26543845e-03,  6.87645486e-03, -9.15402590e-03,  1.56953320e-02,\n",
       "       -1.62544247e-03, -1.44521807e-02,  1.16348660e-03, -6.68551446e-03,\n",
       "        4.95128934e-03,  2.81659268e-03, -1.87381124e-02,  2.13994039e-03,\n",
       "       -5.28821659e-03,  2.47650602e-04,  2.19936223e-03, -1.63506843e-02,\n",
       "       -1.11123302e-02, -2.70500762e-02, -1.00792491e-02,  1.75645076e-02,\n",
       "        2.53906623e-02, -6.69649142e-03,  3.22650594e-05, -1.07612839e-02,\n",
       "        5.64947414e-03, -3.07193097e-03, -2.09563910e-02,  2.09417512e-03,\n",
       "        5.88597838e-03,  4.83782263e-05,  2.32067180e-02, -1.37485376e-03,\n",
       "        2.98667616e-03, -7.71578258e-03,  8.79668030e-04,  1.11911732e-02,\n",
       "        1.17895560e-02,  1.74348059e-02, -3.30588085e-02, -8.34008504e-03,\n",
       "        1.91837817e+00, -6.42994356e-01, -3.46465485e-01, -5.84015294e-01,\n",
       "       -4.87609092e-01, -1.61750041e-01, -7.52815251e-02, -1.63384969e-01,\n",
       "       -3.23981026e-01])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sent_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (features) in enumerate(test_loader):  \n",
    "        features = features.float()\n",
    "\n",
    "        output_sent, output_party = net2(features)\n",
    "\n",
    "        _, predicted_sent = torch.max(output_sent.data, 1)\n",
    "        \n",
    "        predicted_sent_list+=predicted_sent.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment2\n",
       "0           2\n",
       "1           2\n",
       "2           2\n",
       "3           2\n",
       "4           2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_sent = pd.DataFrame(np.vstack(predicted_sent_list).astype('int'))\n",
    "df_pred_sent.columns = ['sentiment2']\n",
    "df_pred_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predicted = pd.concat([test_df, df_pred_sent], sort=False, axis=1)\n",
    "df_test_predicted['sentiment2'] = df_test_predicted['sentiment2'].map(lambda x: sentiment_mapping_reverse[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predicted.to_excel(\"./data/issues_processed_v2_prediction_v2.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
